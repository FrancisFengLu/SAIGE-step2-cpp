<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>SAIGE Step 2: Mathematics Explained</title>

<!-- KaTeX CDN for math rendering -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
  onload="renderMathInElement(document.body, {
    delimiters: [
      {left: '$$', right: '$$', display: true},
      {left: '$', right: '$', display: false}
    ],
    throwOnError: false
  });"></script>

<style>
/* ============================================================
   CSS Variables & Reset
   ============================================================ */
:root {
  --color-vector: #3498db;
  --color-matrix: #27ae60;
  --color-scalar: #e74c3c;
  --color-test: #8e44ad;
  --color-bg: #ffffff;
  --color-sidebar-bg: #1a1a2e;
  --color-sidebar-text: #c8c8e0;
  --color-sidebar-active: #e94560;
  --color-code-bg: #1e1e2e;
  --color-code-text: #cdd6f4;
  --color-border: #e0e0e0;
  --color-section-bg: #f8f9fa;
  --color-heading: #2c3e50;
  --color-note-bg: #fff3cd;
  --color-note-border: #ffc107;
  --sidebar-width: 260px;
  --content-max-width: 900px;
}

* { margin: 0; padding: 0; box-sizing: border-box; }

body {
  font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
  line-height: 1.7;
  color: #333;
  background: var(--color-bg);
}

/* ============================================================
   Sidebar Navigation
   ============================================================ */
#sidebar {
  position: fixed;
  top: 0;
  left: 0;
  width: var(--sidebar-width);
  height: 100vh;
  background: var(--color-sidebar-bg);
  color: var(--color-sidebar-text);
  overflow-y: auto;
  z-index: 1000;
  padding: 20px 0;
  border-right: 3px solid var(--color-sidebar-active);
}

#sidebar h2 {
  color: #fff;
  font-size: 14px;
  text-transform: uppercase;
  letter-spacing: 2px;
  padding: 0 20px 15px;
  border-bottom: 1px solid rgba(255,255,255,0.1);
  margin-bottom: 10px;
}

#sidebar nav a {
  display: block;
  color: var(--color-sidebar-text);
  text-decoration: none;
  padding: 8px 20px;
  font-size: 13px;
  transition: all 0.2s ease;
  border-left: 3px solid transparent;
}

#sidebar nav a:hover {
  background: rgba(255,255,255,0.05);
  color: #fff;
}

#sidebar nav a.active {
  color: #fff;
  background: rgba(233,69,96,0.15);
  border-left-color: var(--color-sidebar-active);
  font-weight: 600;
}

#sidebar nav a.sub {
  padding-left: 36px;
  font-size: 12px;
}

/* ============================================================
   Main Content
   ============================================================ */
#content {
  margin-left: var(--sidebar-width);
  padding: 40px 50px;
  max-width: calc(var(--content-max-width) + 100px + var(--sidebar-width));
}

h1 {
  font-size: 2.2em;
  color: var(--color-heading);
  border-bottom: 3px solid var(--color-sidebar-active);
  padding-bottom: 15px;
  margin-bottom: 30px;
}

h2 {
  font-size: 1.6em;
  color: var(--color-heading);
  margin-top: 50px;
  margin-bottom: 20px;
  padding-top: 15px;
  border-top: 2px solid var(--color-border);
}

h2:first-of-type { border-top: none; margin-top: 20px; }

h3 {
  font-size: 1.25em;
  color: #444;
  margin-top: 30px;
  margin-bottom: 12px;
}

h4 {
  font-size: 1.05em;
  color: #555;
  margin-top: 20px;
  margin-bottom: 8px;
}

p { margin-bottom: 14px; }

section { scroll-margin-top: 20px; }

/* ============================================================
   Color-coded spans for variable types
   ============================================================ */
.vec { color: var(--color-vector); font-weight: 600; }
.mat { color: var(--color-matrix); font-weight: 600; }
.sca { color: var(--color-scalar); font-weight: 600; }
.tst { color: var(--color-test); font-weight: 600; }

.legend {
  display: flex;
  gap: 24px;
  margin: 15px 0 25px;
  padding: 12px 18px;
  background: #f0f0f0;
  border-radius: 6px;
  font-size: 14px;
  flex-wrap: wrap;
}

.legend span {
  display: inline-flex;
  align-items: center;
  gap: 6px;
}

.legend .dot {
  width: 12px;
  height: 12px;
  border-radius: 50%;
  display: inline-block;
}

/* ============================================================
   Code blocks
   ============================================================ */
pre {
  background: var(--color-code-bg);
  color: var(--color-code-text);
  padding: 18px 22px;
  border-radius: 8px;
  overflow-x: auto;
  font-size: 13px;
  line-height: 1.5;
  margin: 16px 0;
  border: 1px solid #313244;
}

code {
  font-family: 'JetBrains Mono', 'Fira Code', 'Cascadia Code', 'Consolas', monospace;
}

p code, li code {
  background: #e8e8e8;
  padding: 1px 6px;
  border-radius: 3px;
  font-size: 0.9em;
  color: #c7254e;
}

/* Syntax highlighting classes */
.kw { color: #cba6f7; }  /* keyword */
.fn { color: #89b4fa; }  /* function */
.cm { color: #6c7086; font-style: italic; }  /* comment */
.st { color: #a6e3a1; }  /* string */
.nu { color: #fab387; }  /* number */
.ty { color: #f9e2af; }  /* type */

/* ============================================================
   Math display blocks
   ============================================================ */
.math-block {
  background: #f7f7ff;
  border: 1px solid #d0d0e0;
  border-left: 4px solid var(--color-test);
  padding: 18px 22px;
  margin: 18px 0;
  border-radius: 0 6px 6px 0;
  overflow-x: auto;
}

.math-block.vec-block { border-left-color: var(--color-vector); }
.math-block.mat-block { border-left-color: var(--color-matrix); }
.math-block.sca-block { border-left-color: var(--color-scalar); }

/* ============================================================
   Collapsible details sections
   ============================================================ */
details {
  margin: 18px 0;
  border: 1px solid var(--color-border);
  border-radius: 6px;
  overflow: hidden;
}

details summary {
  padding: 12px 18px;
  background: #f0f4f8;
  cursor: pointer;
  font-weight: 600;
  color: #444;
  user-select: none;
  transition: background 0.2s;
}

details summary:hover { background: #e4eaf0; }

details[open] summary { border-bottom: 1px solid var(--color-border); }

details .detail-content {
  padding: 18px 22px;
}

/* ============================================================
   Tables
   ============================================================ */
table {
  border-collapse: collapse;
  width: 100%;
  margin: 18px 0;
  font-size: 14px;
}

th, td {
  border: 1px solid #ddd;
  padding: 10px 14px;
  text-align: left;
}

th {
  background: #34495e;
  color: white;
  font-weight: 600;
}

tr:nth-child(even) { background: #f9f9f9; }
tr:hover { background: #f0f4f8; }

/* ============================================================
   Note/callout boxes
   ============================================================ */
.note {
  background: var(--color-note-bg);
  border: 1px solid var(--color-note-border);
  border-left: 4px solid var(--color-note-border);
  padding: 14px 18px;
  border-radius: 0 6px 6px 0;
  margin: 16px 0;
  font-size: 14px;
}

.note strong { color: #856404; }

.insight {
  background: #d4edda;
  border: 1px solid #28a745;
  border-left: 4px solid #28a745;
  padding: 14px 18px;
  border-radius: 0 6px 6px 0;
  margin: 16px 0;
  font-size: 14px;
}

.insight strong { color: #155724; }

/* ============================================================
   SVG pipeline diagram
   ============================================================ */
.pipeline-container {
  width: 100%;
  overflow-x: auto;
  margin: 20px 0 30px;
}

.pipeline-container svg {
  display: block;
  margin: 0 auto;
}

/* ============================================================
   Two-column layout
   ============================================================ */
.two-col {
  display: grid;
  grid-template-columns: 1fr 1fr;
  gap: 20px;
  margin: 16px 0;
}

.two-col > div {
  background: #f8f9fa;
  border: 1px solid #e0e0e0;
  border-radius: 6px;
  padding: 16px;
}

/* ============================================================
   Numerical example boxes
   ============================================================ */
.example {
  background: #eef6ff;
  border: 1px solid #b0d4f1;
  border-left: 4px solid var(--color-vector);
  padding: 18px 22px;
  border-radius: 0 6px 6px 0;
  margin: 18px 0;
}

.example h4 {
  color: var(--color-vector);
  margin-top: 0;
  margin-bottom: 10px;
}

/* ============================================================
   Responsive
   ============================================================ */
@media (max-width: 1000px) {
  #sidebar { display: none; }
  #content { margin-left: 0; padding: 20px; }
  .two-col { grid-template-columns: 1fr; }
}
</style>
</head>
<body>

<!-- ============================================================
     SIDEBAR NAVIGATION
     ============================================================ -->
<div id="sidebar">
  <h2>SAIGE Step 2</h2>
  <nav>
    <a href="#sec-overview">1. Overview &amp; Pipeline</a>
    <a href="#sec-null-model">2. Null Model Input</a>
    <a href="#sec-score-test">3. Score Test</a>
    <a href="#sec-score-fast" class="sub">3a. scoreTestFast</a>
    <a href="#sec-score-noadj" class="sub">3b. noadjCov Path</a>
    <a href="#sec-variance-ratio">4. Variance Ratio</a>
    <a href="#sec-spa">5. Saddlepoint Approx</a>
    <a href="#sec-spa-fast" class="sub">5a. Fast SPA</a>
    <a href="#sec-firth">6. Firth Correction</a>
    <a href="#sec-region">7. Region Testing</a>
    <a href="#sec-p1p2" class="sub">7a. P1Mat / P2Mat</a>
    <a href="#sec-urv" class="sub">7b. URV Collapsing</a>
    <a href="#sec-weights" class="sub">7c. Weights</a>
    <a href="#sec-phi-adj" class="sub">7d. SPA Phi Adjust</a>
    <a href="#sec-burden">8. BURDEN Test</a>
    <a href="#sec-skat">9. SKAT Test</a>
    <a href="#sec-davies" class="sub">9a. Davies Method</a>
    <a href="#sec-liu" class="sub">9b. Liu Fallback</a>
    <a href="#sec-skato">10. SKAT-O</a>
    <a href="#sec-cct">11. CCT</a>
    <a href="#sec-er">12. Efficient Resampling</a>
    <a href="#sec-er-hypergeo" class="sub">12a. HyperGeo Prob</a>
    <a href="#sec-er-exact" class="sub">12b. Exact Enumeration</a>
    <a href="#sec-conditional">13. Conditional Analysis</a>
    <a href="#sec-cond-projection" class="sub">13a. Projection</a>
    <a href="#sec-cond-spa" class="sub">13b. Conditional SPA</a>
    <a href="#sec-sparse-grm">14. Sparse GRM &amp; PCG</a>
    <a href="#sec-pcg" class="sub">14a. PCG Solver</a>
    <a href="#sec-ldmat">15. LD Matrix</a>
    <a href="#sec-validation">16. Validation Summary</a>
    <a href="#sec-appendix">Appendix: Variables</a>
  </nav>
</div>

<!-- ============================================================
     MAIN CONTENT
     ============================================================ -->
<div id="content">

<h1>SAIGE Step 2: Gene-Level Association Testing &mdash; Mathematics Explained</h1>

<p>
This document provides a complete mathematical reference for every formula in the SAIGE Step 2
standalone C++ codebase. Every equation is extracted directly from the source files
(<code>saige_test.cpp</code>, <code>spa_binary.cpp</code>, <code>skat.cpp</code>,
<code>cct.cpp</code>, <code>UTIL.cpp</code>, and <code>main.cpp</code>) and annotated with
variable names, matrix dimensions, and numerical examples.
</p>

<div class="legend">
  <span><span class="dot" style="background:var(--color-vector)"></span> <span class="vec">Vectors [N&times;1]</span></span>
  <span><span class="dot" style="background:var(--color-matrix)"></span> <span class="mat">Matrices [N&times;p]</span></span>
  <span><span class="dot" style="background:var(--color-scalar)"></span> <span class="sca">Scalars</span></span>
  <span><span class="dot" style="background:var(--color-test)"></span> <span class="tst">Test Statistics</span></span>
</div>


<!-- ============================================================
     SECTION 1: OVERVIEW & PIPELINE DIAGRAM
     ============================================================ -->
<section id="sec-overview">
<h2>1. Overview &amp; Data Flow Diagram</h2>

<p>
SAIGE Step 2 takes a fitted null model (from Step 1) and genotype data, then performs either
<strong>single-variant</strong> or <strong>gene/region-based</strong> association testing.
The pipeline is shown below.
</p>

<div class="pipeline-container">
<svg viewBox="0 0 960 480" width="940" height="470" xmlns="http://www.w3.org/2000/svg" font-family="Segoe UI, sans-serif">
  <!-- Background -->
  <rect width="960" height="480" fill="#fafbfc" rx="10"/>

  <!-- Row 1: Inputs -->
  <rect x="20" y="20" width="160" height="60" rx="8" fill="#3498db" stroke="#2980b9" stroke-width="2"/>
  <text x="100" y="45" text-anchor="middle" fill="white" font-size="13" font-weight="bold">Null Model</text>
  <text x="100" y="62" text-anchor="middle" fill="#d5e8f7" font-size="10">mu, res, tau, X, XVX...</text>

  <rect x="200" y="20" width="160" height="60" rx="8" fill="#27ae60" stroke="#219a52" stroke-width="2"/>
  <text x="280" y="45" text-anchor="middle" fill="white" font-size="13" font-weight="bold">Genotype File</text>
  <text x="280" y="55" text-anchor="middle" fill="#c8f0d4" font-size="9">PLINK / VCF / BGEN / PGEN</text>
  <text x="280" y="68" text-anchor="middle" fill="#c8f0d4" font-size="8">.bed .vcf .bgen .pgen</text>

  <rect x="380" y="20" width="160" height="60" rx="8" fill="#e74c3c" stroke="#c0392b" stroke-width="2"/>
  <text x="460" y="45" text-anchor="middle" fill="white" font-size="13" font-weight="bold">Variance Ratios</text>
  <text x="460" y="62" text-anchor="middle" fill="#f5c6cb" font-size="10">MAC categories</text>

  <rect x="560" y="20" width="160" height="60" rx="8" fill="#8e44ad" stroke="#7d3c98" stroke-width="2"/>
  <text x="640" y="45" text-anchor="middle" fill="white" font-size="13" font-weight="bold">Group File</text>
  <text x="640" y="62" text-anchor="middle" fill="#dcc6e8" font-size="10">gene -> variants + annot</text>

  <!-- Optional inputs -->
  <rect x="780" y="20" width="160" height="60" rx="8" fill="#16a085" stroke="#1abc9c" stroke-width="1.5" stroke-dasharray="5,3"/>
  <text x="860" y="40" text-anchor="middle" fill="white" font-size="11" font-weight="bold">Condition Markers</text>
  <text x="860" y="55" text-anchor="middle" fill="#a3e4d7" font-size="9">(optional)</text>
  <text x="860" y="68" text-anchor="middle" fill="#a3e4d7" font-size="8">rs1, rs2, ...</text>

  <!-- Arrows down -->
  <line x1="100" y1="80" x2="100" y2="120" stroke="#888" stroke-width="2" marker-end="url(#arrowhead)"/>
  <line x1="280" y1="80" x2="280" y2="120" stroke="#888" stroke-width="2" marker-end="url(#arrowhead)"/>
  <line x1="460" y1="80" x2="330" y2="120" stroke="#888" stroke-width="2" marker-end="url(#arrowhead)"/>

  <!-- Row 2: Score Test -->
  <rect x="60" y="120" width="300" height="55" rx="8" fill="#34495e" stroke="#2c3e50" stroke-width="2"/>
  <text x="210" y="143" text-anchor="middle" fill="white" font-size="14" font-weight="bold">Score Test</text>
  <text x="210" y="162" text-anchor="middle" fill="#b0bec5" font-size="11">S = g'res/tau, Z = S/sqrt(VR*var)</text>

  <!-- Arrow down from Score Test -->
  <line x1="210" y1="175" x2="210" y2="210" stroke="#888" stroke-width="2" marker-end="url(#arrowhead)"/>

  <!-- Row 3: Decision -->
  <polygon points="210,210 310,240 210,270 110,240" fill="#f39c12" stroke="#e67e22" stroke-width="2"/>
  <text x="210" y="243" text-anchor="middle" fill="white" font-size="11" font-weight="bold">|Z| > cutoff?</text>

  <!-- Left: No SPA (normal approximation) -->
  <line x1="110" y1="240" x2="40" y2="240" stroke="#888" stroke-width="2"/>
  <line x1="40" y1="240" x2="40" y2="310" stroke="#888" stroke-width="2" marker-end="url(#arrowhead)"/>
  <text x="68" y="226" fill="#888" font-size="10">No (|Z| &lt;= cutoff</text>
  <text x="68" y="237" fill="#888" font-size="10">or quant trait)</text>

  <rect x="10" y="310" width="170" height="50" rx="6" fill="#95a5a6" stroke="#7f8c8d" stroke-width="1.5"/>
  <text x="95" y="330" text-anchor="middle" fill="white" font-size="11" font-weight="bold">Normal Approx</text>
  <text x="95" y="347" text-anchor="middle" fill="#d5d8dc" font-size="10">p = P(chi2_1 > Z^2)</text>

  <!-- Right: Yes (binary, |Z| > cutoff) â†’ MAC check -->
  <line x1="310" y1="240" x2="400" y2="240" stroke="#888" stroke-width="2"/>
  <line x1="400" y1="240" x2="400" y2="280" stroke="#888" stroke-width="2" marker-end="url(#arrowhead)"/>
  <text x="340" y="230" fill="#888" font-size="10">Yes (binary)</text>

  <!-- MAC <= 4 decision diamond (comes BEFORE SPA, not after) -->
  <polygon points="400,280 460,305 400,330 340,305" fill="#d35400" stroke="#e67e22" stroke-width="2"/>
  <text x="400" y="308" text-anchor="middle" fill="white" font-size="10" font-weight="bold">MAC &lt;= 4?</text>

  <!-- No branch (MAC > 4): SPA -->
  <line x1="340" y1="305" x2="230" y2="305" stroke="#888" stroke-width="2" marker-end="url(#arrowhead)"/>
  <text x="290" y="298" fill="#888" font-size="10">No (MAC > 4)</text>

  <rect x="180" y="330" width="150" height="50" rx="6" fill="#e74c3c" stroke="#c0392b" stroke-width="1.5"/>
  <text x="255" y="350" text-anchor="middle" fill="white" font-size="11" font-weight="bold">SPA Correction</text>
  <text x="255" y="367" text-anchor="middle" fill="#f5c6cb" font-size="9">(+ Firth if p&lt;0.05)</text>
  <line x1="230" y1="305" x2="230" y2="330" stroke="#888" stroke-width="1.5" marker-end="url(#arrowhead)"/>

  <!-- Yes branch (MAC <= 4): ER Resampling -->
  <line x1="460" y1="305" x2="530" y2="305" stroke="#888" stroke-width="2" marker-end="url(#arrowhead)"/>
  <text x="480" y="298" fill="#888" font-size="10">Yes</text>

  <rect x="480" y="330" width="150" height="50" rx="6" fill="#d35400" stroke="#c0392b" stroke-width="1.5"/>
  <text x="555" y="350" text-anchor="middle" fill="white" font-size="11" font-weight="bold">ER Resampling</text>
  <text x="555" y="367" text-anchor="middle" fill="#f5c6cb" font-size="9">(+ Firth if p&lt;0.05)</text>
  <line x1="530" y1="305" x2="530" y2="330" stroke="#888" stroke-width="1.5" marker-end="url(#arrowhead)"/>

  <!-- Conditional analysis branch (dashed) -->
  <line x1="860" y1="80" x2="860" y2="435" stroke="#16a085" stroke-width="1.5" stroke-dasharray="5,3"/>
  <line x1="860" y1="435" x2="630" y2="435" stroke="#16a085" stroke-width="1.5" stroke-dasharray="5,3" marker-end="url(#arrowhead)"/>
  <rect x="630" y="420" width="160" height="32" rx="6" fill="#16a085" stroke="#1abc9c" stroke-width="1.5" stroke-dasharray="5,3"/>
  <text x="710" y="440" text-anchor="middle" fill="white" font-size="10" font-weight="bold">Conditional Analysis</text>
  <text x="710" y="460" text-anchor="middle" fill="#16a085" font-size="9">BETA_c, SE_c, p.value_c</text>

  <!-- Right branch: Region tests -->
  <line x1="640" y1="80" x2="640" y2="120" stroke="#888" stroke-width="2" marker-end="url(#arrowhead)"/>

  <rect x="530" y="120" width="230" height="55" rx="8" fill="#8e44ad" stroke="#7d3c98" stroke-width="2"/>
  <text x="645" y="143" text-anchor="middle" fill="white" font-size="13" font-weight="bold">Region Test Pipeline</text>
  <text x="645" y="162" text-anchor="middle" fill="#dcc6e8" font-size="11">P1Mat, P2Mat, VarMat, URV</text>

  <!-- Three outputs from Region -->
  <line x1="580" y1="175" x2="520" y2="210" stroke="#888" stroke-width="2" marker-end="url(#arrowhead)"/>
  <line x1="645" y1="175" x2="645" y2="210" stroke="#888" stroke-width="2" marker-end="url(#arrowhead)"/>
  <line x1="710" y1="175" x2="770" y2="210" stroke="#888" stroke-width="2" marker-end="url(#arrowhead)"/>

  <rect x="470" y="210" width="100" height="40" rx="6" fill="#2ecc71" stroke="#27ae60" stroke-width="1.5"/>
  <text x="520" y="234" text-anchor="middle" fill="white" font-size="12" font-weight="bold">BURDEN</text>

  <rect x="595" y="210" width="100" height="40" rx="6" fill="#3498db" stroke="#2980b9" stroke-width="1.5"/>
  <text x="645" y="234" text-anchor="middle" fill="white" font-size="12" font-weight="bold">SKAT</text>

  <rect x="720" y="210" width="100" height="40" rx="6" fill="#9b59b6" stroke="#8e44ad" stroke-width="1.5"/>
  <text x="770" y="234" text-anchor="middle" fill="white" font-size="12" font-weight="bold">SKAT-O</text>

  <!-- CCT combination -->
  <line x1="520" y1="250" x2="520" y2="280" stroke="#888" stroke-width="1.5"/>
  <line x1="645" y1="250" x2="645" y2="280" stroke="#888" stroke-width="1.5"/>
  <line x1="770" y1="250" x2="770" y2="280" stroke="#888" stroke-width="1.5"/>
  <line x1="520" y1="280" x2="770" y2="280" stroke="#888" stroke-width="1.5"/>
  <line x1="645" y1="280" x2="645" y2="310" stroke="#888" stroke-width="2" marker-end="url(#arrowhead)"/>

  <rect x="570" y="310" width="150" height="40" rx="6" fill="#e67e22" stroke="#d35400" stroke-width="1.5"/>
  <text x="645" y="335" text-anchor="middle" fill="white" font-size="12" font-weight="bold">CCT Combination</text>

  <!-- LD Matrix (optional) -->
  <rect x="780" y="310" width="140" height="40" rx="6" fill="#7f8c8d" stroke="#6c7a89" stroke-width="1.5" stroke-dasharray="5,3"/>
  <text x="850" y="328" text-anchor="middle" fill="white" font-size="10" font-weight="bold">LD Matrix</text>
  <text x="850" y="342" text-anchor="middle" fill="#d5d8dc" font-size="8">(optional)</text>
  <line x1="760" y1="160" x2="850" y2="160" stroke="#7f8c8d" stroke-width="1.5" stroke-dasharray="5,3"/>
  <line x1="850" y1="160" x2="850" y2="310" stroke="#7f8c8d" stroke-width="1.5" stroke-dasharray="5,3" marker-end="url(#arrowhead)"/>

  <!-- Arrow marker -->
  <defs>
    <marker id="arrowhead" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
      <polygon points="0 0, 10 3.5, 0 7" fill="#888"/>
    </marker>
  </defs>
</svg>
</div>

</section>


<!-- ============================================================
     SECTION 2: NULL MODEL
     ============================================================ -->
<section id="sec-null-model">
<h2>2. Null Model (Input from Step 1)</h2>

<p>
Step 2 loads the null model fitted in Step 1. The null model provides everything needed
to compute score statistics <em>without</em> re-fitting the model for each variant.
</p>

<div class="note">
<strong>Dimension conventions:</strong>
$N$ = number of samples (individuals) in the study.
$p$ = number of covariates in the null model design matrix, including the intercept
(e.g., if fitting intercept + age + sex, then $p = 3$).
</div>

<table>
<tr><th>Variable</th><th>Type</th><th>Dimension</th><th>Description</th></tr>
<tr><td><span class="vec">mu</span></td><td>vec</td><td>$N$</td><td>Fitted values $\hat{\mu}_i = E[y_i | X_i]$</td></tr>
<tr><td><span class="vec">res</span></td><td>vec</td><td>$N$</td><td>Residuals $r_i = y_i - \hat{\mu}_i$</td></tr>
<tr><td><span class="vec">y</span></td><td>vec</td><td>$N$</td><td>Phenotype values</td></tr>
<tr><td><span class="vec">mu2</span></td><td>vec</td><td>$N$</td><td>Variance weights (C++ name: <code>m_mu2</code>). See Derived Quantities below.</td></tr>
<tr><td><span class="mat">X</span></td><td>mat</td><td>$N \times p$</td><td>Design matrix (intercept + covariates)</td></tr>
<tr><td><span class="mat">XVX</span></td><td>mat</td><td>$p \times p$</td><td>$X^\top V X$ where $V = \text{diag}(\mu_2)$</td></tr>
<tr><td><span class="mat">XXVX_inv</span></td><td>mat</td><td>$N \times p$</td><td>$X (X^\top V X)^{-1}$</td></tr>
<tr><td><span class="mat">XV</span></td><td>mat</td><td>$p \times N$</td><td>$X^\top V = (X^\top \text{diag}(\mu_2))$</td></tr>
<tr><td><span class="mat">XVX_inv_XV</span></td><td>mat</td><td>$p \times N$</td><td>$(X^\top V X)^{-1} X^\top V$</td></tr>
<tr><td><span class="vec">S_a</span></td><td>vec</td><td>$p$</td><td>Score vector $X^\top r$</td></tr>
<tr><td><span class="vec">tau</span></td><td>vec</td><td>$2$</td><td>Variance components $[\tau_0, \tau_1]$</td></tr>
</table>

<h3>Derived Quantities</h3>

<p>
The variance weight vector is stored in C++ as <code>m_mu2</code> (a vector of length $N$).
We write $\texttt{mu2}[i]$ for its $i$-th element to avoid confusion with subscript notation.
</p>

<div class="math-block vec-block">
<strong>Variance weight vector <code>mu2</code></strong> $[N \times 1]$ (binary trait):
$$\texttt{mu2}[i] = \hat{\mu}_i (1 - \hat{\mu}_i)$$
<strong>Variance weight vector <code>mu2</code></strong> $[N \times 1]$ (quantitative trait):
$$\texttt{mu2}[i] = 1/\tau_0 \quad \text{(constant for all } i\text{)}$$
</div>

<h3>Projection Matrix $P$</h3>
<p>
The key operation in the score test is projecting the genotype vector $G$ onto the
space orthogonal to the covariates. The <strong>adjusted genotype</strong> is:
</p>

<div class="math-block mat-block">
$$\tilde{G} = G - X(X^\top V X)^{-1}(X^\top V \cdot G) = G - \texttt{XXVX\_inv} \cdot (\texttt{XV} \cdot G)$$
</div>

<p>
In the code, this is computed by <code>getadjGFast()</code> in <code>saige_test.cpp</code>,
which exploits the sparsity of $G$ by only iterating over non-zero elements:
</p>
<pre><code><span class="kw">void</span> <span class="fn">getadjGFast</span>(<span class="ty">arma::vec</span> &amp; t_GVec, <span class="ty">arma::vec</span> &amp; g, <span class="ty">arma::uvec</span> &amp; iIndex) {
  <span class="ty">arma::vec</span> m_XVG(m_p, <span class="ty">arma::fill::zeros</span>);
  <span class="kw">for</span>(<span class="ty">unsigned int</span> i = <span class="nu">0</span>; i &lt; iIndex.n_elem; i++){
      m_XVG += m_XV.<span class="fn">col</span>(iIndex(i)) * t_GVec(iIndex(i));  <span class="cm">// XV * G (sparse)</span>
  }
  g = t_GVec - m_XXVX_inv * m_XVG;  <span class="cm">// G - XXVX_inv * XV * G</span>
}</code></pre>

</section>


<!-- ============================================================
     SECTION 3: SCORE TEST
     ============================================================ -->
<section id="sec-score-test">
<h2>3. Single-Variant Score Test</h2>

<p>
The score test evaluates $H_0$: the genotype $G$ has no effect on the phenotype, after
accounting for covariates. SAIGE implements three paths:
</p>

<table>
<tr><th>Path</th><th>When Used</th><th>Function</th></tr>
<tr><td><code>scoreTest</code></td><td>Sparse GRM active</td><td>Full $N$-vector computation</td></tr>
<tr><td><code>scoreTestFast</code></td><td>Default (no sparse GRM, with cov adj)</td><td>Sparse exploitation of non-zero genotypes</td></tr>
<tr><td><code>scoreTestFast_noadjCov</code></td><td>No covariate adjustment</td><td>Simplest path</td></tr>
</table>

<h3>Core Formulas (all paths)</h3>

<div class="math-block">
<strong>Score statistic:</strong>
$$\color{#8e44ad}{S} = \frac{\tilde{G}^\top \cdot \color{#3498db}{\text{res}}}{\color{#e74c3c}{\tau_0}}$$

<strong>Unadjusted variance (binary):</strong>
$$\color{#e74c3c}{\text{var}_2} = \sum_i \color{#3498db}{\texttt{mu2}[i]} \cdot \tilde{G}_i^2$$

<strong>Unadjusted variance (quantitative):</strong>
$$\color{#e74c3c}{\text{var}_2} = Z^\top \color{#27ae60}{\text{XVX}} \cdot Z \cdot \tau_0 + G^\top G - 2 B^\top G$$
where $Z = \texttt{XVX\_inv\_XV}^\top \cdot G_1$ and $B = X_1 \cdot Z$.

<strong>Variance-ratio adjusted variance:</strong>
$$\color{#e74c3c}{\text{var}_1} = \color{#e74c3c}{\text{var}_2} \times \color{#e74c3c}{\text{VR}}$$

<strong>Test statistic and p-value:</strong>
$$\color{#8e44ad}{\text{stat}} = \frac{S^2}{\text{var}_1} \sim \chi^2_1 \quad\text{under } H_0$$
$$p = P(\chi^2_1 > \text{stat})$$

<strong>Effect size:</strong>
$$\hat{\beta} = \frac{S}{\text{var}_1}, \qquad \text{SE}(\hat{\beta}) = \frac{|\hat{\beta}|}{\sqrt{|\text{stat}|}}$$
</div>

<section id="sec-score-fast">
<h3>3a. scoreTestFast (default path)</h3>

<p>
This path exploits the sparsity of $G$ by only computing on non-zero indices. Let $I$ be
the set of indices where $G_i \neq 0$. Then:
</p>

<div class="math-block">
$$G_1 = G[I], \quad X_1 = X[I,:], \quad A_1 = \texttt{XVX\_inv\_XV}[I,:]$$
$$Z = A_1^\top G_1, \quad B = X_1 Z, \quad \tilde{G}_1 = G_1 - B$$

<strong>Score (two-part):</strong>
$$S_1 = \text{res}[I]^\top \tilde{G}_1$$
$$S_2 = -(S_a - \text{res}[I]^\top X_1)^\top Z$$
$$S = \frac{S_1 + S_2}{\tau_0}$$

<strong>Variance (binary):</strong>
$$\text{var}_2 = Z^\top (\text{XVX}) Z - \sum_i \texttt{mu2}[I_i] \cdot B_i^2 + \sum_i \texttt{mu2}[I_i] \cdot \tilde{G}_{1,i}^2$$
</div>

</section>

<section id="sec-score-noadj">
<h3>3b. scoreTestFast_noadjCov (no covariate adjustment)</h3>

<p>
When covariate adjustment is disabled, the genotype is not projected. Let $f$ denote the
allele frequency $\texttt{altFreq}$:
</p>

<div class="math-block">
$$S = \frac{G_1^\top \text{res}[I] - \text{sum}(\text{res}) \cdot 2f}{\tau_0}$$

$$\text{var}_2 = \left[\sum_i \texttt{mu2}[I_i] \cdot G_{1,i}^2 - \sum_i \texttt{mu2}[I_i] \cdot 4f \cdot G_{1,i} + \sum_i \texttt{mu2}[i] \cdot 4f^2\right] \cdot \tau_0$$
</div>
</section>

<div class="example">
<h4>Numerical Example: Score Test (N=5, p=2)</h4>
<p>
Consider $N=5$ samples, $p=2$ covariates (intercept + one covariate), binary trait.
</p>
$$G = \begin{pmatrix}0\\1\\0\\2\\0\end{pmatrix}, \quad
\text{res} = \begin{pmatrix}0.3\\-0.2\\0.1\\-0.5\\0.3\end{pmatrix}, \quad
\text{mu2} = \begin{pmatrix}0.21\\0.24\\0.25\\0.16\\0.21\end{pmatrix}, \quad
\tau_0 = 1$$

<p>Non-zero indices: $I = \{1, 3\}$ (0-indexed). Assume $\tilde{G} \approx G$ (identity projection for simplicity).</p>

$$S = \tilde{G}^\top \text{res} = 0 \cdot 0.3 + 1 \cdot (-0.2) + 0 \cdot 0.1 + 2 \cdot (-0.5) + 0 \cdot 0.3 = -1.2$$
$$\text{var}_2 = \sum_i \texttt{mu2}[i] \cdot G_i^2 = 0.24 \cdot 1 + 0.16 \cdot 4 = 0.88$$
$$\text{var}_1 = 0.88 \times \text{VR}$$

<p>If $\text{VR} = 1.02$: $\text{var}_1 = 0.8976$, $\text{stat} = 1.44/0.8976 = 1.604$, $p = P(\chi^2_1 > 1.604) \approx 0.205$.</p>
</div>

</section>


<!-- ============================================================
     SECTION 4: VARIANCE RATIO
     ============================================================ -->
<section id="sec-variance-ratio">
<h2>4. Variance Ratio</h2>

<p>
The variance ratio (VR) corrects for the approximation error introduced by using a mixed model
without the full GRM in computing the variance of the score statistic. It is pre-computed in
Step 1 and depends on the MAC category.
</p>

<div class="math-block sca-block">
$$\text{VR} = \frac{\text{Var}_{\text{exact}}(S)}{\text{Var}_{\text{approx}}(S)}$$

<p>where $\text{Var}_{\text{exact}}$ uses the full GRM (or sparse GRM) and $\text{Var}_{\text{approx}}$ uses only the diagonal/null approximation.</p>
</div>

<h3>MAC-Category Lookup</h3>
<p>
Variance ratios are stored as a vector indexed by MAC category. The lookup in <code>assignVarianceRatio()</code>:
</p>
<pre><code><span class="kw">for</span>(i = <span class="nu">0</span>; i &lt; maxMACVec.n_elem; i++) {
    <span class="kw">if</span>(MAC &lt;= maxMACVec(i) &amp;&amp; MAC &gt; minMACVec(i)) {
        m_varRatioVal = varRatio(i);  <span class="cm">// Found matching category</span>
    }
}</code></pre>

<p>
The adjusted variance is then simply:
</p>
<div class="math-block">
$$\text{var}_1 = \text{var}_2 \times \text{VR}(\text{MAC category})$$
</div>

<div class="note">
<strong>Why is the VR needed?</strong> The exact variance requires $O(N^2)$ computation with the GRM.
The VR pre-computes the ratio once per MAC category on a set of random markers in Step 1,
then applies it as a multiplicative correction in Step 2. This reduces Step 2 to $O(N)$ per marker.
</div>

</section>


<!-- ============================================================
     SECTION 5: SPA
     ============================================================ -->
<section id="sec-spa">
<h2>5. Saddlepoint Approximation (SPA)</h2>

<p>
When $|Z| > \text{SPA\_cutoff}$ (default 2) for binary traits, the normal approximation
to the score test is inaccurate (especially in the tail). SPA provides a more accurate
p-value by using the exact cumulant generating function (CGF) of the test statistic.
</p>

<div class="insight">
<strong>Why SPA?</strong> For binary traits with case-control imbalance (e.g., 1% prevalence),
the distribution of $S = G^\top y$ is highly skewed. The chi-squared(1) approximation
underestimates the tail probability, leading to inflated Type I error. SPA corrects this
by working with the <em>exact</em> CGF of $S$.
</div>

<h3>Cumulant Generating Function (CGF)</h3>
<p>
For binary outcomes, $y_i \sim \text{Bernoulli}(\mu_i)$, so $S = \sum_i g_i y_i$ is a sum of
independent (but not identically distributed) Bernoulli-weighted terms. The CGF is:
</p>

<div class="math-block">
$$K(t) = \sum_{i=1}^N \log\bigl(1 - \mu_i + \mu_i \, e^{g_i t}\bigr)$$

$$K'(t) = \sum_{i=1}^N \frac{\mu_i \, g_i}{(1 - \mu_i) e^{-g_i t} + \mu_i}$$

$$K''(t) = \sum_{i=1}^N \frac{(1-\mu_i)\,\mu_i\,g_i^2\,e^{-g_i t}}{\bigl[(1-\mu_i)e^{-g_i t}+\mu_i\bigr]^2}$$
</div>

<p>Source: <code>Korg_Binom()</code>, <code>K1_adj_Binom()</code>, <code>K2_Binom()</code> in <code>spa_binary.cpp</code>.</p>

<h3>Newton-Raphson Root Finding</h3>
<p>
Find the saddlepoint $\hat{t}$ such that $K'(\hat{t}) = q$ where $q$ is the observed test statistic:
</p>

<div class="math-block">
$$t_{\text{new}} = t - \frac{K'(t) - q}{K''(t)}$$

<p>Iterate until $|t_{\text{new}} - t| < \text{tol}$ (where $\text{tol} = \epsilon^{0.25} \approx 1.22 \times 10^{-4}$).</p>

<p><strong>Bisection safeguard:</strong> If the sign of $K'(t)-q$ changes between iterations and the
jump exceeds the previous jump, halve the step size.</p>
</div>

<p>Source: <code>getroot_K1_Binom()</code> in <code>spa_binary.cpp</code>.</p>

<h3>Lugannani-Rice Formula</h3>
<p>
Given the saddlepoint $\hat{\zeta}$, compute the tail probability:
</p>

<div class="math-block">
$$w = \text{sign}(\hat{\zeta}) \cdot \sqrt{2(\hat{\zeta} \cdot q - K(\hat{\zeta}))}$$
$$v = \hat{\zeta} \cdot \sqrt{K''(\hat{\zeta})}$$
$$Z_{\text{test}} = w + \frac{1}{w} \ln\!\left(\frac{v}{w}\right)$$

<p><strong>One-sided p-value:</strong></p>
$$p_{\text{upper}} = \begin{cases}
\Phi(-Z_{\text{test}}) & \text{if } Z_{\text{test}} > 0 \\
-\Phi(Z_{\text{test}}) & \text{if } Z_{\text{test}} \leq 0
\end{cases}$$
<p>where $\Phi$ is the standard normal CDF.</p>
</div>

<h3>Two-Sided P-Value</h3>
<p>
SAIGE computes two-sided p-values by finding saddlepoints for both $q$ and its reflection $q_{\text{inv}}$:
</p>

<div class="math-block">
$$q = \frac{S}{\sqrt{\text{var}_1/\text{var}_2}} + m_1, \qquad m_1 = \mu^\top \tilde{G}$$
$$q_{\text{inv}} = \begin{cases}
-|q - m_1| + m_1 & \text{if } q > m_1 \\
|q - m_1| + m_1 & \text{if } q < m_1 \\
m_1 & \text{if } q = m_1
\end{cases}$$

$$p_{\text{SPA}} = |p_1(q)| + |p_2(q_{\text{inv}})|$$
</div>

<p>Source: <code>SPA_binary()</code> in <code>spa_binary.cpp</code>.</p>

<section id="sec-spa-fast">
<h3>5a. Fast SPA Variant</h3>

<p>
When more than 50% of genotype elements are zero (<code>p_iIndexComVecSize &ge; 0.5</code>),
the fast SPA variant is used. It splits samples into non-zero ($B$) and zero ($A$) groups
and approximates the zero-genotype group with a normal distribution:
</p>

<div class="math-block">
$$K_{\text{fast}}(t) = \underbrace{\sum_{i \in B} \log(1 - \mu_i + \mu_i e^{g_i t})}_{\text{exact for non-zero}} + \underbrace{\text{NAmu} \cdot t + \tfrac{1}{2}\text{NAsigma} \cdot t^2}_{\text{normal approx for zero}}$$

<p>where:</p>
$$\text{NAmu} = m_1 - \sum_{i \in B} g_i \mu_i, \qquad \text{NAsigma} = \text{var}_2 - \sum_{i \in B} \mu_i(1-\mu_i) g_i^2$$
</div>

<p>
The fast variant K', K'' functions similarly add the normal approximation terms ($\text{NAmu} + \text{NAsigma} \cdot t$
for K', and $\text{NAsigma}$ for K''). Source: <code>Korg_fast_Binom()</code>, <code>K1_adj_fast_Binom()</code>,
<code>K2_fast_Binom()</code>.
</p>

</section>

<details>
<summary>Full derivation: Why does the Lugannani-Rice formula work?</summary>
<div class="detail-content">
<p>
The saddlepoint approximation is derived from the inversion formula for the CGF.
The probability $P(S > q)$ can be expressed via the inverse Fourier transform of the
moment generating function $M(t) = e^{K(t)}$:
</p>
$$P(S > q) = \frac{1}{2\pi i} \int_{c-i\infty}^{c+i\infty} \frac{e^{K(t) - tq}}{t}\,dt$$
<p>
The saddlepoint $\hat{\zeta}$ is chosen to minimize $K(t) - tq$, which means $K'(\hat{\zeta}) = q$.
Expanding $K(t) - tq$ around $\hat{\zeta}$ to second order and performing the integral via
the method of steepest descent gives the Lugannani-Rice formula. The key insight is that
the transformed variable $Z_{\text{test}}$ has an approximately standard normal distribution,
making $\Phi(-Z_{\text{test}})$ an excellent approximation even in the extreme tails.
</p>
<p>
The formula has relative error $O(N^{-3/2})$ compared to $O(N^{-1/2})$ for the normal approximation,
which is critical when computing p-values of $10^{-10}$ or smaller.
</p>
</div>
</details>

</section>


<!-- ============================================================
     SECTION 6: FIRTH CORRECTION
     ============================================================ -->
<section id="sec-firth">
<h2>6. Firth Correction</h2>

<p>
When the SPA p-value for a binary trait falls below a cutoff (default $p < 0.05$),
SAIGE applies Firth's penalized logistic regression to obtain a less biased effect size estimate.
This corrects the small-sample bias of maximum likelihood estimation, which is particularly
problematic for rare variants with extreme case-control imbalance.
</p>

<h3>Penalized Logistic Regression</h3>

<div class="math-block">
<p><strong>Penalized score equation:</strong></p>
$$U^*(\beta) = X^\top \left[(y - \pi) + h \odot (0.5 - \pi)\right] = 0$$

<p>where $\pi_i = \text{logit}^{-1}(x_i^\top \beta + \text{offset}_i)$, $h_i$ are the hat matrix
diagonal elements, and $\odot$ denotes element-wise multiplication.</p>

<p><strong>Hat matrix diagonal:</strong></p>
$$h = \text{diag}(Q Q^\top), \quad \text{where } QR = X \cdot \text{diag}(\sqrt{W})$$
$$W_i = \pi_i(1 - \pi_i)$$

<p><strong>Fisher information:</strong></p>
$$\mathcal{I} = (X \cdot \text{diag}(\sqrt{W}))^\top (X \cdot \text{diag}(\sqrt{W}))$$

<p><strong>Newton update:</strong></p>
$$\delta = \mathcal{I}^{-1} U^*, \quad \beta_{\text{new}} = \beta + \delta$$
<p>(with step-size limiting: $\|\delta\|_\infty \leq \texttt{maxstep}$)</p>
</div>

<p>Source: <code>fast_logistf_fit_simple()</code> in <code>saige_test.cpp</code>.</p>

<div class="note">
<strong>Important:</strong> The Firth correction only adjusts $\hat{\beta}$. The SE is
<em>back-calculated</em> from the SPA p-value: $\text{SE} = |\hat{\beta}_{\text{Firth}}| / |z_{\alpha/2}|$
where $z_{\alpha/2}$ is from the SPA p-value. This preserves the SPA's accurate p-value
while providing the less-biased Firth effect estimate.
</div>

</section>


<!-- ============================================================
     SECTION 7: REGION TESTING PIPELINE
     ============================================================ -->
<section id="sec-region">
<h2>7. Region/Gene-Based Testing Pipeline</h2>

<p>
Region-based testing evaluates whether a <em>set</em> of variants (e.g., all rare variants
in a gene) is collectively associated with the phenotype. The pipeline has these stages:
</p>

<ol>
  <li>Read the <strong>group file</strong> defining genes, their variants, annotations, and weights</li>
  <li>For each variant: QC (MAC, MAF, missing rate), score test, classify as regular or ultra-rare</li>
  <li>Stratify by <strong>annotation &times; MAF threshold</strong> combinations</li>
  <li>Collapse ultra-rare variants (URVs) into a single pseudo-marker per stratum</li>
  <li>Build <span class="mat">P1Mat</span>, <span class="mat">P2Mat</span>, <span class="mat">VarMat</span></li>
  <li>Apply weights and SPA Phi adjustment</li>
  <li>Run BURDEN / SKAT / SKAT-O tests</li>
  <li>Combine across strata via CCT</li>
</ol>

<section id="sec-p1p2">
<h3>7a. Score Vector and Variance-Covariance Matrix Construction</h3>

<p>
For each non-URV marker $j$ in the region, after computing the score test, we store two matrices:
</p>

<div class="math-block mat-block">
<p><strong>P1Mat</strong> $[m \times N]$: each row is a scaled adjusted genotype</p>
$$\texttt{P1Mat}[j,:] = \sqrt{\text{VR}_j} \cdot \tilde{G}_j^\top$$

<p><strong>P2Mat</strong> $[N \times m]$: each column is a scaled P2 vector</p>
$$\texttt{P2Mat}[:,j] = \sqrt{\text{VR}_j} \cdot \text{P2Vec}_j$$

<p>where for binary traits without sparse GRM:</p>
$$\text{P2Vec}_j = \tilde{G}_j \odot \text{mu2} \cdot \tau_0$$

<p><strong>Variance-covariance matrix</strong> $\Phi$ $[m \times m]$:</p>
$$\color{#27ae60}{\Phi} = \texttt{P1Mat} \cdot \texttt{P2Mat}$$
</div>

<p>Source: <code>mainRegionInCPP()</code> in <code>main.cpp</code> lines 1746-1748, and VarMat construction at line 2050.</p>

<div class="note">
<strong>Chunking:</strong> For large genes with many markers, the matrices are computed in chunks
of size <code>g_region_maxMarkers_cutoff</code> and saved to disk, then assembled via block
matrix multiplication: $\Phi_{ij} = P1_{\text{chunk}_i} \cdot P2_{\text{chunk}_j}$.
</div>

</section>

<section id="sec-urv">
<h3>7b. Ultra-Rare Variant (URV) Collapsing</h3>

<p>
Variants with MAC &leq; <code>g_region_minMAC_cutoff</code> (typically 10) are too rare to
test individually. They are collapsed into a single pseudo-marker per annotation&times;MAF stratum.
</p>

<div class="math-block">
<p><strong>Collapsing method</strong> (<code>method_to_CollapseUltraRare = "max"</code>):</p>
$$\text{genoUR}_{i,\text{jm}} = \max_{k \in \text{URV}(i,\text{jm})} G_{i,k}$$

<p>For each sample $i$ and annotation&times;MAF stratum $\text{jm}$, take the maximum dosage
across all URVs belonging to that stratum. This preserves the "presence of any rare variant"
signal while avoiding double-counting.</p>
</div>

<p>
After collapsing, the URV pseudo-marker is tested just like a regular marker: it gets its own
score test, P1Mat/P2Mat entries, and is included in the SKAT/BURDEN tests.
</p>

</section>

<section id="sec-weights">
<h3>7c. Weights</h3>

<p>
Each variant is weighted using the Beta density function evaluated at its MAF:
</p>

<div class="math-block sca-block">
$$w_j = f_{\text{Beta}}(\text{MAF}_j;\; a_1, a_2)$$

<p>Default parameters: $a_1 = 1, a_2 = 25$.</p>

$$f_{\text{Beta}}(x; 1, 25) = 25(1-x)^{24}$$
</div>

<p>
This strongly upweights rare variants. For example:
</p>
<table>
<tr><th>MAF</th><th>$w = 25(1-\text{MAF})^{24}$</th></tr>
<tr><td>0.0001</td><td>24.94</td></tr>
<tr><td>0.001</td><td>24.41</td></tr>
<tr><td>0.01</td><td>19.37</td></tr>
<tr><td>0.05</td><td>7.14</td></tr>
<tr><td>0.1</td><td>1.94</td></tr>
<tr><td>0.5</td><td>$\approx 0$</td></tr>
</table>

<p>Source: <code>getWeights()</code> in <code>UTIL.cpp</code>, weight computation in <code>mainRegionInCPP()</code> line 1692.</p>

<p>The weighted score and variance matrix are:</p>
<div class="math-block">
$$\text{Score}_{\text{weighted}} = S \odot w$$
$$\Phi_{\text{weighted}} = (w \cdot w^\top) \odot \Phi$$
</div>

</section>

<section id="sec-phi-adj">
<h3>7d. SPA Phi Adjustment</h3>

<p>
For binary traits, the normal-approximation-based $\Phi$ matrix needs correction using
SPA p-values. This two-step adjustment is performed by <code>SPA_ER_kernel_related_Phiadj_fast_new()</code>:
</p>

<div class="math-block">
<p><strong>Step 1: Per-variant scale factor</strong></p>
<p>For each variant $j$ with SPA log-p-value $\ln(p_j)$:</p>
$$\text{VarS}_{\text{new},j} = \frac{S_j^2}{F^{-1}_{\chi^2_1}(1 - p_j)}$$
$$\text{scaleFactor}_j = \sqrt{\frac{\text{VarS}_{\text{new},j}}{\text{VarS}_{\text{org},j}}}$$

<p>where $\text{VarS}_{\text{org},j} = \Phi_{jj}$ (diagonal of original $\Phi$) and
$F^{-1}_{\chi^2_1}$ is the chi-squared(1) quantile function.</p>

<p><strong>Step 2: Burden-based global correction</strong></p>
$$\Phi_{\text{adj}} = \text{scaleFactor} \cdot \text{scaleFactor}^\top \odot \Phi$$
$$\text{VarQ} = \text{sum}(\Phi_{\text{adj}}), \qquad Q_b = (\sum_j S_j)^2$$
$$\text{VarQ}_2 = \frac{Q_b}{F^{-1}_{\chi^2_1}(1 - p_{\text{burden,SPA}})}$$
$$r = \min\!\left(1, \;\frac{\text{VarQ}}{\text{VarQ}_2}\right)$$

$$\color{#27ae60}{\Phi_{\text{ccadj}}} = \frac{\Phi_{\text{adj}}}{r}$$
</div>

<p>Source: <code>SPA_ER_kernel_related_Phiadj_fast_new()</code> and <code>get_newPhi_scaleFactor_traitType()</code> in <code>main.cpp</code>.</p>

<details>
<summary>Intuition: Why adjust Phi?</summary>
<div class="detail-content">
<p>
The variance-covariance matrix $\Phi$ is constructed using the score-test normal approximation.
But for binary traits with case-control imbalance, SPA shows that the actual variance differs
from the normal approximation. The adjustment rescales each entry of $\Phi$ so that:
</p>
<ol>
  <li>The diagonal matches the SPA-corrected variance (step 1)</li>
  <li>The total variance of the burden statistic matches the SPA burden p-value (step 2)</li>
</ol>
<p>
The ratio $r$ ensures that the rescaled $\Phi$ is consistent with the SPA burden test.
When $r < 1$, the normal approximation underestimates the variance, and dividing by $r$ inflates
$\Phi$ to match.
</p>
</div>
</details>

</section>
</section>


<!-- ============================================================
     SECTION 8: BURDEN TEST
     ============================================================ -->
<section id="sec-burden">
<h2>8. BURDEN Test</h2>

<p>
The BURDEN test collapses all variants in a group into a single aggregate score.
It is the special case of SKAT-O with $\rho = 1$.
</p>

<div class="math-block">
<p><strong>Test statistic:</strong></p>
$$T_{\text{Burden}} = \left(\sum_{j=1}^m S_j\right)^2$$

<p><strong>Null distribution:</strong></p>
$$\text{Var}_{\text{Burden}} = \sum_{i,j} \Phi_{ij} = \mathbf{1}^\top \Phi \, \mathbf{1}$$

$$\frac{T_{\text{Burden}}}{\text{Var}_{\text{Burden}}} \sim \chi^2_1 \quad \text{under } H_0$$

<p><strong>P-value:</strong></p>
$$p = P\!\left(\chi^2_1 > \frac{T_{\text{Burden}}}{\text{Var}_{\text{Burden}}}\right)$$

<p><strong>Effect size and SE:</strong></p>
$$\hat{\beta}_{\text{Burden}} = \frac{\sum_j S_j}{\text{tr}(\Phi)}$$

$$\text{SE}_{\text{Burden}} = \frac{|\hat{\beta}_{\text{Burden}}|}{|\Phi^{-1}(p/2)|}$$
<p>where $\Phi^{-1}$ is the standard normal quantile function.</p>
</div>

<p>Source: <code>get_SKAT_pvalue()</code> in <code>skat.cpp</code> lines 631-663.</p>

<div class="example">
<h4>Numerical Example: Burden Test (m=3 variants)</h4>
$$S = \begin{pmatrix}-0.5\\0.8\\-0.3\end{pmatrix}, \quad
\Phi = \begin{pmatrix}0.10 & 0.02 & 0.01\\0.02 & 0.15 & 0.03\\0.01 & 0.03 & 0.08\end{pmatrix}$$

$$T_{\text{Burden}} = (-0.5 + 0.8 - 0.3)^2 = 0^2 = 0$$
$$\text{Var}_{\text{Burden}} = 0.10+0.15+0.08+2(0.02+0.01+0.03) = 0.45$$
$$p = P(\chi^2_1 > 0/0.45) = P(\chi^2_1 > 0) = 1.0$$

<p>A non-trivial example with $S = (1.2, 0.8, 0.5)^\top$:</p>
$$T_{\text{Burden}} = (1.2 + 0.8 + 0.5)^2 = 6.25$$
$$p = P(\chi^2_1 > 6.25/0.45) = P(\chi^2_1 > 13.89) \approx 1.9 \times 10^{-4}$$
</div>

</section>


<!-- ============================================================
     SECTION 9: SKAT TEST
     ============================================================ -->
<section id="sec-skat">
<h2>9. SKAT Test</h2>

<p>
SKAT (Sequence Kernel Association Test) uses a quadratic form that preserves the
individual variant contributions, unlike BURDEN which sums them. It is more powerful
when variants have mixed effect directions.
</p>

<div class="math-block">
<p><strong>Test statistic:</strong></p>
$$Q_{\text{SKAT}} = S^\top S = \sum_{j=1}^m S_j^2$$

<p><strong>Null distribution:</strong></p>
$$Q_{\text{SKAT}} \sim \sum_{j=1}^m \lambda_j \chi^2_{1,j} \quad \text{under } H_0$$
<p>where $\lambda_1 \geq \lambda_2 \geq \cdots \geq \lambda_m > 0$ are the eigenvalues of $\Phi$,
and $\chi^2_{1,j}$ are independent chi-squared(1) random variables.</p>
</div>

<p>
Computing $P(Q > q)$ for a mixture of chi-squareds is non-trivial. SAIGE uses two methods:
Davies (primary) and Liu (fallback).
</p>

<section id="sec-davies">
<h3>9a. Davies Method (Characteristic Function Inversion)</h3>

<p>
The Davies method computes the tail probability by numerically inverting the characteristic
function of $Q$.
</p>

<div class="math-block">
<p><strong>Characteristic function of $Q = \sum \lambda_j \chi^2_{n_j}(\delta_j)$:</strong></p>
$$\phi_Q(t) = \prod_{j=1}^m (1 - 2it\lambda_j)^{-n_j/2} \exp\!\left(\frac{i \delta_j t \lambda_j}{1 - 2it\lambda_j}\right)$$

<p><strong>Tail probability via inversion:</strong></p>
$$P(Q > c) = \frac{1}{2} - \frac{1}{\pi} \int_0^\infty \frac{\text{Im}[\phi_Q(t) \cdot e^{-itc}]}{t}\,dt$$

<p><strong>In polar form, the integrand is:</strong></p>
$$f(t) = \frac{\exp(\text{log\_amp}) \cdot \sin(\text{phase})}{t}$$

<p>where (for SAIGE's case: $n_j=1$, $\delta_j=0$):</p>
$$\text{log\_amp} = \sum_{j=1}^m -\frac{1}{4} \log(1 + 4t^2\lambda_j^2)$$
$$\text{phase} = \sum_{j=1}^m \frac{1}{2} \arctan(2t\lambda_j) - tc$$
</div>

<p>
The integral is evaluated by the <strong>trapezoidal rule</strong> with adaptive step size:
</p>

<pre><code><span class="cm">// Step size: h = pi / (4 * max_eigenvalue) to satisfy Nyquist</span>
<span class="ty">double</span> h = <span class="nu">1.0</span> / (<span class="nu">2.0</span> * almx);
h = <span class="fn">std::min</span>(h, M_PI / (<span class="nu">4.0</span> * lmax));

<span class="kw">for</span> (<span class="ty">int</span> k = <span class="nu">1</span>; k &lt;= lim; k++) {
    <span class="ty">double</span> t = k * h;
    integral += <span class="fn">compute_integrand</span>(t, params);  <span class="cm">// sin(phase)*exp(log_amp)/t</span>
}
pvalue = <span class="nu">0.5</span> - h * integral / M_PI;</code></pre>

<p>Source: <code>davies_impl::compute()</code> in <code>skat.cpp</code>.</p>

</section>

<section id="sec-liu">
<h3>9b. Liu Moment-Matching Method (Fallback)</h3>

<p>
When Davies fails to converge or returns invalid results, Liu's method approximates the
mixture of chi-squareds by matching the first four cumulants to a scaled (non-central)
chi-squared distribution.
</p>

<div class="math-block">
<p><strong>Cumulant sums:</strong></p>
$$c_k = \sum_{j=1}^m \lambda_j^k \quad \text{for } k = 1, 2, 3, 4$$

<p><strong>Skewness and kurtosis ratios:</strong></p>
$$s_1 = \frac{c_3}{c_2^{3/2}}, \qquad s_2 = \frac{c_4}{c_2^2}$$

<p><strong>If $s_1^2 > s_2$:</strong> Noncentral chi-squared fit</p>
$$a = \frac{1}{s_1 - \sqrt{s_1^2 - s_2}}, \quad \delta = s_1 a^3 - a^2, \quad \ell = a^2 - 2\delta$$

<p><strong>If $s_1^2 \leq s_2$:</strong> Central chi-squared fit</p>
$$\delta = 0, \quad \ell = 1/s_1^2$$

<p><strong>Normalized statistic:</strong></p>
$$Q_{\text{norm}} = \frac{Q - \mu_Q}{\sigma_Q} \cdot \sqrt{2\ell + 4\delta} + \ell + \delta$$
<p>where $\mu_Q = c_1$ and $\sigma_Q = \sqrt{2c_2}$.</p>

<p><strong>P-value:</strong></p>
$$p = P(\chi^2_\ell(\delta) > Q_{\text{norm}})$$
</div>

<p>Source: <code>liu_pvalue()</code> in <code>skat.cpp</code>.</p>

</section>

<div class="example">
<h4>Numerical Example: SKAT Test (m=3 variants)</h4>
$$S = \begin{pmatrix}1.5\\-0.8\\0.3\end{pmatrix}, \quad \lambda = \begin{pmatrix}0.15\\0.10\\0.05\end{pmatrix} \text{ (eigenvalues of } \Phi\text{)}$$

$$Q_{\text{SKAT}} = 1.5^2 + 0.8^2 + 0.3^2 = 2.25 + 0.64 + 0.09 = 2.98$$

<p><strong>Davies method computes:</strong></p>
<p>$P(0.15\chi^2_1 + 0.10\chi^2_1 + 0.05\chi^2_1 > 2.98)$ via numerical integration.</p>

<p><strong>Liu fallback:</strong></p>
$$c_1 = 0.30, \; c_2 = 0.035, \; c_3 = 0.005, \; c_4 = 0.0008$$
$$\mu_Q = 0.30, \; \sigma_Q = \sqrt{0.07} = 0.265$$
$$s_1 = 0.005/0.035^{1.5} = 0.765, \; s_2 = 0.0008/0.035^2 = 0.653$$
<p>Since $s_1^2 = 0.585 < s_2 = 0.653$: use central chi-squared with $\ell = 1/0.585 = 1.71$.</p>
$$Q_{\text{norm}} = \frac{2.98 - 0.30}{0.265}\sqrt{3.42} + 1.71 = 10.12 \cdot 1.850 + 1.71 \approx 20.4$$
$$p = P(\chi^2_{1.71} > 20.4) \approx 1.8 \times 10^{-5}$$
</div>

</section>


<!-- ============================================================
     SECTION 10: SKAT-O
     ============================================================ -->
<section id="sec-skato">
<h2>10. SKAT-O (Optimal Unified Test)</h2>

<p>
SKAT-O interpolates between SKAT ($\rho=0$) and BURDEN ($\rho=1$) to find the optimal
balance. It is the most powerful test when the true effect pattern is unknown.
</p>

<div class="math-block">
<p><strong>Combined test statistic:</strong></p>
$$Q(\rho) = (1-\rho) \underbrace{S^\top S}_{Q_{\text{SKAT}}} + \rho \underbrace{(\mathbf{1}^\top S)^2}_{Q_{\text{Burden}}}$$

<p><strong>Rho grid (11 points):</strong></p>
$$\rho \in \{0,\; 0.01,\; 0.04,\; 0.09,\; 0.16,\; 0.25,\; 0.36,\; 0.49,\; 0.64,\; 0.81,\; 1\}$$
<p>(These are $\{0, 0.1^2, 0.2^2, \ldots, 0.9^2, 1\}$)</p>

<p><strong>Null distribution:</strong></p>
$$Q(\rho) \sim \sum_j \lambda_j(\rho) \chi^2_{1,j}$$
<p>where $\lambda_j(\rho)$ are eigenvalues of $R_\rho^{1/2} \Phi \, R_\rho^{1/2}$ and
$R_\rho = (1-\rho)I + \rho \mathbf{1}\mathbf{1}^\top$.</p>
</div>

<h3>Algorithm</h3>
<ol>
  <li>For each $\rho_k$ in the grid, compute $Q(\rho_k)$ and its p-value $p_k$ via Davies/Liu</li>
  <li>Find $T_{\min} = \min_k p_k$</li>
  <li>Compute the SKAT-O p-value: $P(\min_k p(\rho_k) < T_{\min})$</li>
</ol>

<h3>SKAT-O P-Value Computation</h3>

<div class="math-block">
<p><strong>Decomposition:</strong> For each $\rho_k$, decompose $Q(\rho_k) = \lambda_{\max,k} Z + Q_{\text{remain},k}$
where $Z \sim \chi^2_1$ is the leading eigenvalue component.</p>

<p><strong>Integration:</strong></p>
$$p_{\text{SKAT-O}} = \int_0^\infty \max_k P(Q_{\text{remain},k} > \tau_k - \lambda_{\max,k} z) \cdot f_{\chi^2_1}(z)\,dz$$

<p>where $\tau_k$ is the threshold such that $P(Q(\rho_k) > \tau_k) = T_{\min}$ under the
Liu approximation, and $f_{\chi^2_1}$ is the chi-squared(1) density.</p>

<p>The integral is evaluated via a grid with step $\Delta x = 0.05$ from 0 to 40,
using chi-squared(1) CDF weights:
$$p_{\text{SKAT-O}} \approx \sum_{i=0}^{799} \max_k P(Q_{\text{remain},k} > \tau_k - \lambda_{\max,k} x_{\text{mid},i}) \cdot [F_{\chi^2_1}(x_{i+1}) - F_{\chi^2_1}(x_i)]$$
</p>
</div>

<p>Source: <code>SKATO_optimal_pvalue()</code> in <code>skat.cpp</code>.</p>

<details>
<summary>Eigenvalues of $R_\rho^{1/2} \Phi R_\rho^{1/2}$ for general $\rho$</summary>
<div class="detail-content">
<p>
The correlation matrix $R_\rho = (1-\rho)I + \rho \mathbf{1}\mathbf{1}^\top$ has eigenvalues:
</p>
<ul>
  <li>$(1-\rho)$ with multiplicity $m-1$ (eigenvectors orthogonal to $\mathbf{1}$)</li>
  <li>$(1-\rho + m\rho)$ with multiplicity 1 (eigenvector $\mathbf{1}/\sqrt{m}$)</li>
</ul>
<p>
The square root is:
$$R_\rho^{1/2} = \sqrt{1-\rho}\left(I - \frac{\mathbf{1}\mathbf{1}^\top}{m}\right) + \sqrt{1-\rho+m\rho}\;\frac{\mathbf{1}\mathbf{1}^\top}{m}$$
</p>
<p>
The eigenvalues $\lambda_j(\rho)$ are then eigenvalues of $R_\rho^{1/2} \Phi R_\rho^{1/2}$, computed
via <code>compute_phi_rho_eigenvalues()</code> in <code>skat.cpp</code>.
</p>
</div>
</details>

</section>


<!-- ============================================================
     SECTION 11: CCT
     ============================================================ -->
<section id="sec-cct">
<h2>11. Cauchy Combination Test (CCT)</h2>

<p>
CCT combines p-values from different annotation&times;MAF strata into a single omnibus
p-value. It uses the Cauchy distribution because it is the only stable distribution
for which the sum of independent Cauchy variables is also Cauchy (up to scale), and
it is robust to correlated test statistics.
</p>

<div class="math-block">
<p><strong>CCT statistic:</strong></p>
$$T_{\text{CCT}} = \sum_{i=1}^k w_i \tan\!\bigl((0.5 - p_i)\pi\bigr)$$

<p>where $w_i = 1/k$ (equal weights) and $p_i$ are the individual p-values.</p>

<p><strong>For very small p-values</strong> ($p_i < 10^{-16}$), to avoid numerical issues with $\tan$:</p>
$$w_i \tan\!\bigl((0.5 - p_i)\pi\bigr) \approx \frac{w_i}{p_i \pi}$$

<p><strong>CCT p-value:</strong></p>
$$p_{\text{CCT}} = \begin{cases}
\displaystyle 1 - F_{\text{Cauchy}}(T_{\text{CCT}}) & \text{if } T_{\text{CCT}} \leq 10^{15} \\[8pt]
\displaystyle \frac{1}{T_{\text{CCT}} \cdot \pi} & \text{if } T_{\text{CCT}} > 10^{15}
\end{cases}$$

<p>where $F_{\text{Cauchy}}$ is the CDF of the standard Cauchy(0,1) distribution.</p>
</div>

<h3>Edge Cases</h3>
<ul>
  <li><strong>Any $p_i = 0$:</strong> $p_{\text{CCT}} = 0$</li>
  <li><strong>Any $p_i = 1$:</strong> Use Bonferroni instead: $p_{\text{CCT}} = \min(1, k \cdot p_{\min})$</li>
</ul>

<p>Source: <code>CCT_cpp()</code> in <code>cct.cpp</code>.</p>

<div class="example">
<h4>Numerical Example: CCT (k=3 p-values)</h4>
$$p = (0.002, \; 0.05, \; 0.30)$$
$$T_{\text{CCT}} = \frac{1}{3}\left[\tan((0.5 - 0.002)\pi) + \tan((0.5 - 0.05)\pi) + \tan((0.5 - 0.30)\pi)\right]$$
$$= \frac{1}{3}\left[\tan(0.498\pi) + \tan(0.45\pi) + \tan(0.20\pi)\right]$$
$$= \frac{1}{3}\left[159.1 + 6.31 + 0.727\right] = \frac{166.1}{3} = 55.38$$

$$p_{\text{CCT}} = 1 - F_{\text{Cauchy}}(55.38) = \frac{1}{\pi}\arctan(1/55.38) \approx 0.00575$$
</div>

<div class="insight">
<strong>Why Cauchy?</strong> The sum $\sum w_i \tan((0.5 - p_i)\pi)$ has a standard Cauchy
distribution under the global null (all $p_i$ uniform), regardless of the correlation structure
between the test statistics. This makes CCT valid even when the strata are correlated (as they
typically are, since the variant sets overlap across MAF thresholds). Other combination methods
(Fisher, Tippett) require independence.
</div>

</section>


<!-- ============================================================
     SECTION 12: EFFICIENT RESAMPLING (ER)
     ============================================================ -->
<section id="sec-er">
<h2>12. Efficient Resampling (ER) for Binary Rare Variants</h2>

<p>
When testing binary traits with extremely rare variants (MAC &leq; <code>MACCutoffforER</code>,
default 4), the SPA approximation becomes unreliable because the test statistic takes on only
a handful of discrete values. SAIGE uses <strong>Efficient Resampling (ER)</strong> to compute
an exact (or near-exact) p-value by enumerating all possible case/control assignments weighted
by their probabilities under the null model.
</p>

<div class="insight">
<strong>Why ER?</strong> For a variant with MAC = 1, the genotype vector has only one non-reference
allele carrier. The score statistic $S = G^\top y$ can take at most 2 distinct values (carrier is a
case or a control). SPA, which relies on a smooth CGF, cannot accurately approximate such a
discrete distribution. ER instead computes the exact null distribution.
</div>

<h3>Overview of <code>SKATExactBin_Work()</code></h3>

<p>
The main entry point is <code>SKATExactBin_Work()</code> in <code>er_binary.cpp</code>. Given $k$ carriers
of the rare variant and $n$ total samples with $n_{\text{case}}$ cases, it:
</p>

<ol>
  <li>Computes the weighted hypergeometric probability $P(\text{carriers among cases} = j)$ for $j = 0, 1, \ldots, k$</li>
  <li>Enumerates all $\binom{k}{j}$ ways to assign $j$ carriers among the $k$ positions, for each $j$</li>
  <li>For each assignment, computes the SKAT-like test statistic $Q = \|Z_{\text{test}}\|^2$</li>
  <li>Weights each $Q$ by its Fisher probability (odds-based)</li>
  <li>Computes the exact p-value as $P(Q \geq Q_{\text{obs}})$ under the weighted null</li>
</ol>

<div class="math-block">
<p><strong>Test statistic for each permutation:</strong></p>
<p>For an assignment where carriers indexed by $\{a_1, \ldots, a_j\}$ are cases:</p>
$$Z_{\text{test}} = Z_0 + \sum_{i=1}^{j} (Z_1[a_i] - Z_0[a_i])$$
$$Q = \|Z_{\text{test}}\|^2 = \sum_{l=1}^{m} Z_{\text{test},l}^2$$

<p>where $Z_0[i] = -\pi_i \cdot G_i$ (expected contribution if carrier $i$ is a control)
and $Z_1[i] = (1-\pi_i) \cdot G_i$ (expected contribution if carrier $i$ is a case),
with $\pi_i = \hat{\mu}_i$ the null model fitted probability for sample $i$.</p>

<p><strong>Final p-value:</strong></p>
$$p_{\text{ER}} = \sum_{\{Q_r \geq Q_{\text{obs}}\}} w_r - \frac{1}{2}\sum_{\{Q_r = Q_{\text{obs}}\}} w_r$$
<p>where $w_r$ are the normalized Fisher probabilities (odds-weighted) for each possible assignment.</p>
</div>

<p>Source: <code>SKATExactBin_Work()</code> in <code>er_binary.cpp</code> lines 770-832.</p>

<section id="sec-er-hypergeo">
<h3>12a. Hypergeometric Probability Computation</h3>

<p>
The <code>HyperGeo</code> class computes weighted hypergeometric probabilities, which give the null
distribution of how many carriers fall among the cases. Samples are grouped into $G$ bins by
their null probabilities $\pi_i$, and within each bin, the combinatorial probability is computed.
</p>

<div class="math-block">
<p><strong>Log-probability table construction:</strong></p>
<p>For each group $g$ with $n_g$ samples and average odds $w_g = \bar{\pi}_g / (1 - \bar{\pi}_g)$:</p>
$$\text{table}[g][j] = \log\binom{n_g}{j} + j \cdot \log(w_g)$$

<p><strong>Recursive enumeration:</strong></p>
<p>For groups $g = 0, 1, \ldots, G-1$, recursively enumerate all ways to distribute
$n_{\text{case}}$ cases across groups. For the last group ($g = G-1$), the count is
determined: $j_{G-1} = n_{\text{case}} - \sum_{g'<G-1} j_{g'}$.</p>

$$P(k \text{ carriers among cases}) = \frac{\sum_{\text{valid combos}} \exp(\text{log-prob})}{\sum_{k'} \sum_{\text{valid combos}} \exp(\text{log-prob})}$$

<p><strong>Log-combination function:</strong></p>
$$\log\binom{n}{k} = \sum_{d=1}^{k} [\log(n - d + 1) - \log(d)]$$
</div>

<p>Source: <code>HyperGeo::Run()</code>, <code>HyperGeo::Recursive()</code>, <code>HyperGeo::lCombinations()</code> in <code>er_binary.cpp</code> lines 167-274.</p>

<pre><code><span class="kw">int</span> <span class="fn">HyperGeo::Recursive</span>(<span class="kw">double</span> lprob, <span class="kw">int</span> idx, <span class="kw">int</span> ncase_used) {
    <span class="kw">int</span> num = m_group[idx];
    <span class="kw">if</span> (idx == m_ngroup - <span class="nu">1</span>) {
        lprob1 = <span class="fn">GetLogProb</span>(idx, ncase_used);
        <span class="fn">SaveProb</span>(lprob + lprob1, ncase_used);  <span class="cm">// Accumulate exp(lprob - ref)</span>
        <span class="kw">return</span> <span class="nu">1</span>;
    }
    <span class="kw">for</span> (i = <span class="nu">0</span>; i &lt;= num; i++) {
        <span class="kw">if</span> (ncase_used + i &lt;= m_ncase) {
            lprob1 = <span class="fn">GetLogProb</span>(idx, i);
            <span class="fn">Recursive</span>(lprob + lprob1, idx+<span class="nu">1</span>, ncase_used + i);
        }
    }
}</code></pre>

</section>

<section id="sec-er-exact">
<h3>12b. Exact Enumeration and Resampling</h3>

<p>
The <code>ComputeExact</code> class handles the actual enumeration of all $\binom{k}{j}$ carrier
assignments for each $j$. For small $k$ (MAC &leq; 4 means $k \leq 4$), the total number of
combinations is manageable: $\sum_{j=0}^{4}\binom{4}{j} = 16$.
</p>

<div class="math-block">
<p><strong>Total combinations per $k$:</strong></p>
$$N_{\text{total}} = \sum_{j=0}^{k} \binom{k}{j} = 2^k$$

<p>For $k = 1$: 2 combinations. For $k = 2$: 4. For $k = 3$: 8. For $k = 4$: 16.</p>

<p><strong>Fisher probability for each assignment:</strong></p>
<p>If $j$ carriers out of $k$ are cases, and the selected carriers have indices $\{a_1, \ldots, a_j\}$:</p>
$$\text{FisherProb} = \prod_{i=1}^{j} \text{odds}_{a_i}, \quad \text{where } \text{odds}_i = \frac{\pi_i}{1 - \pi_i}$$

<p><strong>Inverse enumeration</strong> (for $j > k/2$, enumerate controls instead for efficiency):</p>
$$\text{FisherProb}_{\text{inv}} = \frac{\prod_{\text{all}} \text{odds}_i}{\prod_{l=1}^{k-j} \text{odds}_{b_l}}$$
<p>where $\{b_1, \ldots, b_{k-j}\}$ are the non-case carriers.</p>
</div>

<p>
When $N_{\text{total}}$ exceeds the resampling budget (<code>NResampling</code>, default 10000),
some strata switch from exact enumeration to Monte Carlo resampling. The
<code>SKAT_Resampling()</code> function randomly samples carrier assignments, weighted
by the hypergeometric probabilities.
</p>

<p>Source: <code>ComputeExact::Run()</code>, <code>SKAT_Exact_Recurse()</code>, <code>CalTestStat()</code>,
<code>CalFisherProb()</code> in <code>er_binary.cpp</code> lines 280-589.</p>

<div class="example">
<h4>Numerical Example: ER with MAC = 2</h4>
<p>
Suppose $k = 2$ carriers at positions $\{3, 7\}$ in a cohort of $N = 100$ with
$n_{\text{case}} = 20$. Null probabilities: $\pi_3 = 0.15$, $\pi_7 = 0.25$.
</p>
<p>Odds: $o_3 = 0.15/0.85 = 0.176$, $o_7 = 0.25/0.75 = 0.333$.</p>
<p>Possible assignments ($j$ = number of carrier-cases):</p>
$$j=0: \binom{2}{0}=1 \text{ way}, \quad j=1: \binom{2}{1}=2 \text{ ways}, \quad j=2: \binom{2}{2}=1 \text{ way}$$
<p>Fisher probabilities: $j=0$: $1.0$ (baseline); $j=1$: $\{o_3, o_7\} = \{0.176, 0.333\}$; $j=2$: $o_3 \cdot o_7 = 0.059$.</p>
<p>After normalization and weighting by hypergeometric $P(j)$, the test statistic for each of the 4
assignments is compared to $Q_{\text{obs}}$ to yield the exact p-value.</p>
</div>

<div class="note">
<strong>Interaction with SPA/Firth:</strong> When ER is used, the p-value replaces the SPA p-value.
The SE is back-calculated from the ER p-value: $\text{SE} = |\hat{\beta}| / |\Phi^{-1}(p_{\text{ER}}/2)|$.
If the Firth correction is also active (p &lt; <code>pCutoffforFirth</code>), the Firth-adjusted beta
is combined with the ER p-value for the SE.
</div>

</section>
</section>


<!-- ============================================================
     SECTION 13: CONDITIONAL ANALYSIS
     ============================================================ -->
<section id="sec-conditional">
<h2>13. Conditional Analysis</h2>

<p>
Conditional analysis tests whether a marker has an independent effect after accounting for
the effects of one or more <strong>conditioning markers</strong>. This is used to determine whether
a significant signal at a locus is driven by a single causal variant or by multiple independent
signals. The conditioning markers' genotypes are loaded and their score test statistics pre-computed
during initialization via <code>assignConditionFactors()</code>.
</p>

<h3>Setup: Conditioning Factor Matrices</h3>

<p>
Let $G_2$ be the $[N \times c]$ genotype matrix of $c$ conditioning markers. During initialization,
the following quantities are pre-computed and stored:
</p>

<div class="math-block mat-block">
<p><strong>Pre-computed conditioning matrices:</strong></p>
$$\texttt{P2Mat\_cond} \;[N \times c]: \text{P2 vectors of conditioning markers}$$
$$\texttt{VarMat\_cond} \;[c \times c]: \text{variance-covariance of conditioning markers}$$
$$\texttt{VarInvMat\_cond} \;[c \times c] = \texttt{VarMat\_cond}^{-1}$$
$$\texttt{Tstat\_cond} \;[c]: \text{score statistics of conditioning markers}$$
</div>

<p>Source: <code>assignConditionFactors()</code> in <code>saige_test.cpp</code> lines 942-962.</p>

<section id="sec-cond-projection">
<h3>13a. Conditional Score and Variance Projection</h3>

<p>
For each test marker with adjusted genotype $\tilde{G}_1$ and unconditional statistics
$(S, \text{var}_1)$, the conditional statistics are obtained by projecting out the
conditioning markers' contribution:
</p>

<div class="math-block">
<p><strong>Cross-covariance (G1 with conditioning markers):</strong></p>
$$\texttt{G1P2} = \sqrt{\text{VR}} \cdot \tilde{G}_1^\top \cdot \texttt{P2Mat\_cond} \quad [1 \times c]$$

<p><strong>Conditional score statistic:</strong></p>
$$S_c = S - \texttt{G1P2} \cdot \texttt{VarInvMat\_cond} \cdot \texttt{Tstat\_cond}$$

<p><strong>Conditional variance:</strong></p>
$$\text{var}_c = \text{var}_1 - \texttt{G1P2} \cdot \texttt{VarInvMat\_cond} \cdot \texttt{G1P2}^\top$$

<p><strong>Conditional test statistic and p-value:</strong></p>
$$\text{stat}_c = \frac{S_c^2}{\text{var}_c} \sim \chi^2_1 \quad\text{under } H_0$$
$$p_c = P(\chi^2_1 > \text{stat}_c)$$

<p><strong>Conditional effect size:</strong></p>
$$\hat{\beta}_c = \frac{S_c}{\text{var}_c}, \qquad \text{SE}_c = \frac{|\hat{\beta}_c|}{\sqrt{\text{stat}_c}}$$
</div>

<p>Source: <code>getMarkerPval()</code> conditional branch in <code>saige_test.cpp</code> lines 670-726.</p>

<pre><code><span class="cm">// Conditional projection (from saige_test.cpp)</span>
t_G1tilde_P_G2tilde = <span class="fn">sqrt</span>(m_varRatioVal) * t_gtilde.<span class="fn">t</span>() * m_P2Mat_cond;
<span class="ty">arma::vec</span> t_Tstat_ctemp = t_G1tilde_P_G2tilde * m_VarInvMat_cond * m_Tstat_cond;
t_Tstat_c = t_Tstat - t_Tstat_ctemp(<span class="nu">0</span>);
<span class="ty">arma::vec</span> t_varT_ctemp = t_G1tilde_P_G2tilde * m_VarInvMat_cond * (t_G1tilde_P_G2tilde.<span class="fn">t</span>());
t_varT_c = t_var1 - t_varT_ctemp(<span class="nu">0</span>);</code></pre>

<div class="note">
<strong>Self-conditioning:</strong> When a test marker is also a conditioning marker, $\texttt{G1P2}$
is proportional to a row of $\texttt{VarMat\_cond}$, and the conditional variance approaches zero.
Both R and C++ output $p_c = 1.0$ for these markers.
</div>

</section>

<section id="sec-cond-spa">
<h3>13b. Conditional SPA (Binary Traits)</h3>

<p>
For binary traits where the conditional test statistic exceeds the SPA cutoff
($\text{stat}_c > \text{SPA\_cutoff}^2$), SPA is applied to the conditional
score statistic using the same CGF machinery but with the conditional $q$ value:
</p>

<div class="math-block">
$$q_c = \frac{S_c}{\sqrt{\text{var}_c / \text{var}_2}} + m_1, \qquad m_1 = \mu^\top \tilde{G}$$

<p>The reflection $q_{\text{inv},c}$ and two-sided SPA p-value are computed
identically to the unconditional case (Section 5), but using $q_c$ instead of $q$.</p>
</div>

<p>Source: <code>getMarkerPval()</code> conditional SPA branch in <code>saige_test.cpp</code> lines 729-780.</p>

</section>

<div class="example">
<h4>Numerical Example: Conditional Analysis (c=2 conditioning markers)</h4>
<p>Unconditional statistics for test marker: $S = 2.5$, $\text{var}_1 = 0.80$.</p>
<p>Conditioning markers' score statistics: $T_{\text{cond}} = (1.8, 0.9)^\top$.</p>
$$\texttt{VarInvMat\_cond} = \begin{pmatrix}1.3 & -0.2\\-0.2 & 1.1\end{pmatrix}, \quad
\texttt{G1P2} = (0.15, \; 0.08)$$

$$S_c = 2.5 - (0.15, 0.08) \begin{pmatrix}1.3 & -0.2\\-0.2 & 1.1\end{pmatrix} \begin{pmatrix}1.8\\0.9\end{pmatrix}
= 2.5 - (0.15, 0.08) \begin{pmatrix}2.16\\0.63\end{pmatrix}
= 2.5 - 0.374 = 2.126$$

$$\text{var}_c = 0.80 - (0.15, 0.08) \begin{pmatrix}1.3 & -0.2\\-0.2 & 1.1\end{pmatrix} \begin{pmatrix}0.15\\0.08\end{pmatrix}
= 0.80 - 0.0326 = 0.767$$

$$\text{stat}_c = 2.126^2 / 0.767 = 5.89, \quad p_c = P(\chi^2_1 > 5.89) \approx 0.015$$
</div>

</section>


<!-- ============================================================
     SECTION 14: SPARSE GRM AND PCG
     ============================================================ -->
<section id="sec-sparse-grm">
<h2>14. Sparse GRM and Preconditioned Conjugate Gradient (PCG)</h2>

<p>
When the null model was fitted with a sparse GRM (genetic relationship matrix), the variance
computation in the score test changes. Instead of using the diagonal approximation
$P_2 = \tilde{G} \odot \text{mu2} \cdot \tau_0$, the exact variance requires solving
a linear system involving the sparse covariance matrix $\Sigma$.
</p>

<h3>Score Test with Sparse GRM</h3>

<p>
The <code>scoreTest()</code> function in <code>saige_test.cpp</code> handles this path when
<code>flagSparseGRM_cur = true</code>:
</p>

<div class="math-block">
<p><strong>Score (same as standard path):</strong></p>
$$S = \frac{\tilde{G}^\top \cdot \text{res}}{\tau_0}$$

<p><strong>P2 vector via PCG solve:</strong></p>
$$\Sigma \cdot P_2 = \tilde{G} \quad \Longrightarrow \quad P_2 = \Sigma^{-1} \tilde{G}$$

<p><strong>Unadjusted variance:</strong></p>
$$\text{var}_2 = \tilde{G}^\top \cdot P_2$$

<p><strong>Projection correction (when isVarPsadj = true):</strong></p>
$$\text{var}_2 = \text{var}_2 - \tilde{G}^\top \cdot (\Sigma^{-1} X)(X^\top \Sigma^{-1} X)^{-1} X^\top \cdot P_2$$

<p><strong>VR-adjusted variance:</strong></p>
$$\text{var}_1 = \text{var}_2 \times \text{VR}_{\text{sparse}}$$
</div>

<p>Source: <code>scoreTest()</code> in <code>saige_test.cpp</code> lines 125-200.</p>

<pre><code><span class="cm">// Sparse GRM branch in scoreTest()</span>
<span class="kw">if</span> (!m_flagSparseGRM_cur) {
    t_P2Vec = t_gtilde % m_mu2 * m_tauvec[<span class="nu">0</span>];      <span class="cm">// diagonal approx</span>
} <span class="kw">else</span> {
    t_P2Vec = <span class="fn">getPCG1ofSigmaAndGtilde</span>(t_gtilde, <span class="nu">100</span>, <span class="nu">0.02</span>);  <span class="cm">// PCG solve</span>
}</code></pre>

<section id="sec-pcg">
<h3>14a. PCG Iterative Solver</h3>

<p>
The Preconditioned Conjugate Gradient (PCG) method solves $\Sigma x = b$ iteratively, where
$\Sigma$ is the sparse covariance matrix (stored as <code>m_spSigmaMat</code>).
The preconditioner is the diagonal of $\Sigma$ (Jacobi preconditioner).
</p>

<div class="math-block">
<p><strong>PCG Algorithm:</strong></p>
<p>Given: sparse $\Sigma \in \mathbb{R}^{N \times N}$, right-hand side $b \in \mathbb{R}^N$,
preconditioner $M = \text{diag}(\Sigma)$.</p>

$$x_0 = 0, \quad r_0 = b, \quad z_0 = M^{-1} r_0, \quad p_0 = z_0$$

<p><strong>For $k = 0, 1, 2, \ldots$ until $\|r_k\|^2 < \text{tol}$ or $k \geq \text{maxiter}$:</strong></p>
$$\alpha_k = \frac{r_k^\top z_k}{p_k^\top (\Sigma \, p_k)}$$
$$x_{k+1} = x_k + \alpha_k \, p_k$$
$$r_{k+1} = r_k - \alpha_k \, (\Sigma \, p_k)$$
$$z_{k+1} = M^{-1} r_{k+1}$$
$$\beta_k = \frac{z_{k+1}^\top r_{k+1}}{z_k^\top r_k}$$
$$p_{k+1} = z_{k+1} + \beta_k \, p_k$$

<p>Default: <code>maxiterPCG = 100</code>, <code>tolPCG = 0.02</code>.</p>
</div>

<p>Source: <code>getPCG1ofSigmaAndGtilde()</code> in <code>saige_test.cpp</code> lines 1079-1110.</p>

<pre><code><span class="ty">arma::vec</span> <span class="fn">SAIGEClass::getPCG1ofSigmaAndGtilde</span>(<span class="ty">arma::vec</span>&amp; bVec,
                                                <span class="kw">int</span> maxiterPCG, <span class="kw">double</span> tolPCG) {
    <span class="ty">arma::vec</span> xVec(Nnomissing, <span class="ty">arma::fill::zeros</span>);
    <span class="ty">arma::vec</span> rVec = bVec;
    <span class="ty">arma::vec</span> minvVec = <span class="nu">1.0</span> / m_diagSigma;   <span class="cm">// Jacobi preconditioner</span>
    <span class="ty">arma::vec</span> zVec = minvVec % rVec;
    <span class="ty">arma::vec</span> pVec = zVec;
    <span class="kw">while</span> (sumr2 &gt; tolPCG &amp;&amp; iter &lt; maxiterPCG) {
        <span class="ty">arma::vec</span> ApVec = m_spSigmaMat * pVec;     <span class="cm">// sparse mat-vec</span>
        <span class="kw">double</span> alpha = <span class="fn">dot</span>(rVec, zVec) / <span class="fn">dot</span>(pVec, ApVec);
        xVec += alpha * pVec;
        r1Vec = rVec - alpha * ApVec;
        z1Vec = minvVec % r1Vec;
        <span class="kw">double</span> beta = <span class="fn">dot</span>(z1Vec, r1Vec) / <span class="fn">dot</span>(zVec, rVec);
        pVec = z1Vec + beta * pVec;
        <span class="cm">// ...</span>
    }
    <span class="kw">return</span> xVec;
}</code></pre>

</section>

<div class="note">
<strong>Sparse GRM lower triangle issue:</strong> R's <code>dsTMatrix</code> stores only the lower
triangle of the sparse sigma matrix. Both R SAIGE and our converter pass only these entries to
<code>arma::sp_mat</code>, creating a non-symmetric matrix. For markers with MAC &leq; 20
and p &lt; 0.05, both R and C++ enter the PCG (scoreTest) path. The non-symmetry causes
PCG convergence issues for some markers, resulting in negative variance (p = 1). This
is a known SAIGE behavior that we replicate faithfully.
</div>

<h3>Fast Test Re-evaluation</h3>

<p>
When <code>isFastTest = true</code> (the default for sparse GRM models), markers are first tested
using <code>scoreTestFast()</code> (the fast algebraic path without PCG). Markers whose fast-path
p-value falls below <code>pval_cutoff_for_fastTest</code> (default 0.05) are then re-evaluated
using the full <code>scoreTest()</code> with PCG. This two-pass approach avoids running the
expensive PCG solver for the vast majority of non-significant markers.
</p>

<div class="math-block sca-block">
<p><strong>Re-evaluation criterion:</strong></p>
$$\text{If } p_{\text{fast}} < 0.05 \text{ and MAC} \in [\text{minMACVec}, \text{maxMACVec}] \text{ for sparse VR: re-run with PCG}$$
</div>

</section>


<!-- ============================================================
     SECTION 15: LD MATRIX COMPUTATION
     ============================================================ -->
<section id="sec-ldmat">
<h2>15. LD Matrix Computation</h2>

<p>
The LD matrix module computes the genotype correlation structure ($G^\top G$) between all
variant pairs in a region. This is used for downstream meta-analysis (e.g., combining
SAIGE results across cohorts). The computation is performed by <code>LDmatRegionInCPP()</code>
in <code>ldmat.cpp</code>.
</p>

<h3>Algorithm</h3>

<div class="math-block mat-block">
<p><strong>LD matrix definition:</strong></p>
<p>For $m$ markers passing QC in a region, with genotype vectors $G_1, G_2, \ldots, G_m \in \mathbb{R}^N$:</p>
$$\Phi_{\text{LD}}[i,j] = G_i^\top G_j$$

<p>This is the unnormalized LD matrix (not the correlation $r^2$ but the raw dosage product).</p>

<p><strong>Chunked computation:</strong></p>
<p>Markers are processed in chunks of size $m_1$ (default: <code>g_region_maxMarkers_cutoff</code>).
Each chunk's genotype matrix is stored as a sparse integer matrix $P_{\text{chunk}}$
($m_{\text{chunk}} \times N$, stored in Armadillo sparse format). The LD matrix is then assembled
via block multiplication:</p>
$$\Phi_{\text{LD}}[\text{block}_{ij}] = P_{\text{chunk}_i} \cdot P_{\text{chunk}_j}^\top$$

<p>Only the lower triangle ($i \geq j$) is stored and output.</p>
</div>

<h3>Output Files</h3>

<table>
<tr><th>File</th><th>Format</th><th>Contents</th></tr>
<tr><td><code>{prefix}.marker_info.txt</code></td><td>Tab-separated</td><td>CHR, POS, Alleles, MAC, N, MissingRate per marker</td></tr>
<tr><td><code>{prefix}.LDmat.txt</code></td><td>COO sparse</td><td>Lower-triangular entries: <code>row col value</code></td></tr>
<tr><td><code>{prefix}.index.txt</code></td><td>Space-separated</td><td>Start/end row indices per region</td></tr>
</table>

<p>Source: <code>LDmatRegionInCPP()</code> in <code>ldmat.cpp</code> lines 98-419.</p>

<pre><code><span class="cm">// Chunked LD matrix assembly (from ldmat.cpp)</span>
<span class="kw">for</span> (<span class="ty">unsigned int</span> index1 = <span class="nu">0</span>; index1 &lt; nchunks; index1++) {
    P1Mat.<span class="fn">load</span>(P1MatFile);                      <span class="cm">// Load chunk i</span>
    <span class="kw">for</span> (<span class="ty">unsigned int</span> index2 = <span class="nu">0</span>; index2 &lt; index1; index2++) {
        P2Mat.<span class="fn">load</span>(P2MatFile);                  <span class="cm">// Load chunk j</span>
        offVarMat = P1Mat * (P2Mat.<span class="fn">t</span>());       <span class="cm">// Off-diagonal block</span>
    }
    diagVarMat = P1Mat * (P1Mat.<span class="fn">t</span>());           <span class="cm">// Diagonal block</span>
}</code></pre>

<div class="note">
<strong>Marker QC:</strong> Markers are filtered by the same QC criteria as region testing
(missing rate, MAF, MAC, imputation info score) before inclusion in the LD matrix.
Markers failing QC have <code>NaN</code> in the MAC column and are excluded from the output.
</div>

</section>


<!-- ============================================================
     SECTION 16: VALIDATION SUMMARY
     ============================================================ -->
<section id="sec-validation">
<h2>16. Validation Summary</h2>

<p>
The C++ standalone implementation was validated against R SAIGE (version 1.5.1) across 12 test
configurations covering all code paths. The comparison pipeline is in <code>test/run_comparison.sh</code>.
Both R and C++ use the same null model (extracted from SAIGE's .rda files via
<code>convert_rda_to_arma.R</code>).
</p>

<table>
<tr>
  <th>Test</th>
  <th>Configuration</th>
  <th>Markers</th>
  <th>Result</th>
  <th>Notes</th>
</tr>
<tr>
  <td><strong>1</strong></td>
  <td>Quant + Single-Variant</td>
  <td>128,868</td>
  <td style="background:#d4edda; color:#155724"><strong>ALL EXACT</strong></td>
  <td>644,340/644,340 values, 0 difference</td>
</tr>
<tr>
  <td><strong>2</strong></td>
  <td>Binary + Single-Variant</td>
  <td>70</td>
  <td style="background:#d4edda; color:#155724"><strong>ALL EXACT</strong></td>
  <td>350/350 values incl. SPA, Firth, ER</td>
</tr>
<tr>
  <td><strong>3</strong></td>
  <td>Quant + Region</td>
  <td>2 regions</td>
  <td style="background:#d4edda; color:#155724"><strong>PASS</strong></td>
  <td>BURDEN/SKAT pass; SKAT-O ~5% (Liu approx)</td>
</tr>
<tr>
  <td><strong>4</strong></td>
  <td>Binary + Region</td>
  <td>2 regions</td>
  <td style="background:#d4edda; color:#155724"><strong>PASS</strong></td>
  <td>BURDEN/SKAT pass; SKAT-O ~8.5% (Liu + SPA Phi)</td>
</tr>
<tr>
  <td><strong>5</strong></td>
  <td>Sparse GRM + Single-Variant</td>
  <td>128,868</td>
  <td style="background:#d4edda; color:#155724"><strong>ALL EXACT</strong></td>
  <td>scoreTestFast + PCG re-evaluation paths</td>
</tr>
<tr>
  <td><strong>6</strong></td>
  <td>Sparse GRM + noadjCov</td>
  <td>128,868</td>
  <td style="background:#d4edda; color:#155724"><strong>ALL EXACT</strong></td>
  <td>scoreTestFast_noadjCov for 122,021 markers</td>
</tr>
<tr>
  <td><strong>7</strong></td>
  <td>Conditional Analysis</td>
  <td>128,865 + 3 cond</td>
  <td style="background:#d4edda; color:#155724"><strong>ALL EXACT</strong></td>
  <td>10 columns (5 uncond + 5 cond)</td>
</tr>
<tr>
  <td><strong>8</strong></td>
  <td>Multi-VR Categories</td>
  <td>128,868</td>
  <td style="background:#d4edda; color:#155724"><strong>ALL EXACT</strong></td>
  <td>2 MAC categories, 18,449 markers used different VR</td>
</tr>
<tr>
  <td><strong>9</strong></td>
  <td>Efficient Resampling (ER)</td>
  <td>70</td>
  <td style="background:#d4edda; color:#155724"><strong>PASS</strong></td>
  <td>Validated via Test 2 (MAC &leq; 4 markers)</td>
</tr>
<tr>
  <td><strong>10</strong></td>
  <td>LD Matrix</td>
  <td>99 (2 genes)</td>
  <td style="background:#d4edda; color:#155724"><strong>PASS</strong></td>
  <td>3 output files generated correctly</td>
</tr>
<tr>
  <td><strong>11</strong></td>
  <td>Survival Trait</td>
  <td>--</td>
  <td style="background:#f8d7da; color:#721c24"><strong>NOT IMPL</strong></td>
  <td>SPA dispatcher throws; niche use case</td>
</tr>
<tr>
  <td><strong>12</strong></td>
  <td>Non-PLINK Formats</td>
  <td>128,868 each</td>
  <td style="background:#d4edda; color:#155724"><strong>ALL EXACT</strong></td>
  <td>VCF (htslib), BGEN (zstd), PGEN (built-in)</td>
</tr>
</table>

<h3>Region Test Detailed Results</h3>

<div class="two-col">
<div>
<h4>Test 3: Quant + Region</h4>
<table>
<tr><th>Column</th><th>Max Rel Error</th><th>Status</th></tr>
<tr><td>BETA_Burden</td><td>$6.9 \times 10^{-7}$</td><td>PASS</td></tr>
<tr><td>Pvalue_Burden</td><td>$4.9 \times 10^{-4}$</td><td>PASS</td></tr>
<tr><td>Pvalue_SKAT</td><td>$2.8 \times 10^{-3}$</td><td>PASS</td></tr>
<tr><td>Pvalue_SKAT-O</td><td>$5.2 \times 10^{-2}$</td><td>APPROX</td></tr>
<tr><td>SE_Burden</td><td>$1.1 \times 10^{-3}$</td><td>CLOSE</td></tr>
</table>
</div>
<div>
<h4>Test 4: Binary + Region</h4>
<table>
<tr><th>Column</th><th>Max Rel Error</th><th>Status</th></tr>
<tr><td>BETA_Burden</td><td>$3.0 \times 10^{-6}$</td><td>EXACT</td></tr>
<tr><td>Pvalue_Burden</td><td>$3.2 \times 10^{-4}$</td><td>PASS</td></tr>
<tr><td>Pvalue_SKAT</td><td>$2.0 \times 10^{-6}$</td><td>EXACT</td></tr>
<tr><td>Pvalue_SKAT-O</td><td>$8.5 \times 10^{-2}$</td><td>APPROX</td></tr>
<tr><td>SE_Burden</td><td>$4.9 \times 10^{-4}$</td><td>PASS</td></tr>
</table>
</div>
</div>

<div class="note">
<strong>SKAT-O approximation error:</strong> The ~5-8% relative error in SKAT-O p-values is due to the
Liu moment-matching method used to compute quantiles in the SKAT-O integration (Section 10).
Using exact Davies quantiles was tested but caused a 13x runtime increase for only 0.5% improvement.
This is an acceptable tradeoff for a practical implementation.
</div>

<h3>Genotype Format Equivalence</h3>

<p>
All four supported genotype formats (PLINK, VCF, BGEN, PGEN) produce identical output when reading
the same underlying genotype data. This was verified by MD5 comparison of output files for 128,868
markers.
</p>

<table>
<tr><th>Format</th><th>Library</th><th>Config Key</th><th>Status</th></tr>
<tr><td>PLINK (.bed/.bim/.fam)</td><td>Built-in</td><td><code>plinkFile</code></td><td>Reference</td></tr>
<tr><td>VCF/BCF/VCF.GZ</td><td>htslib</td><td><code>vcfFile</code>, <code>vcfField</code></td><td>EXACT match</td></tr>
<tr><td>BGEN v1.2</td><td>zstd + zlib</td><td><code>bgenFile</code></td><td>EXACT match</td></tr>
<tr><td>PGEN (.pgen/.pvar/.psam)</td><td>Built-in</td><td><code>pgenFile</code></td><td>EXACT match</td></tr>
</table>

</section>


<!-- ============================================================
     APPENDIX: COMPLETE VARIABLE REFERENCE
     ============================================================ -->
<section id="sec-appendix">
<h2>Appendix: Complete Variable Cross-Reference</h2>

<table>
<tr><th>C++ Variable</th><th>Math Symbol</th><th>Dimension</th><th>Source File</th></tr>
<tr><td><code>m_mu</code></td><td>$\hat{\mu}$</td><td>$N$</td><td>saige_test.hpp</td></tr>
<tr><td><code>m_res</code></td><td>$r = y - \hat{\mu}$</td><td>$N$</td><td>saige_test.hpp</td></tr>
<tr><td><code>m_mu2</code></td><td>$\hat{\mu}(1-\hat{\mu})$</td><td>$N$</td><td>saige_test.hpp</td></tr>
<tr><td><code>m_y</code></td><td>$y$</td><td>$N$</td><td>saige_test.hpp</td></tr>
<tr><td><code>m_tauvec</code></td><td>$\tau$</td><td>$2$</td><td>saige_test.hpp</td></tr>
<tr><td><code>m_XVX</code></td><td>$X^\top V X$</td><td>$p \times p$</td><td>saige_test.hpp</td></tr>
<tr><td><code>m_XXVX_inv</code></td><td>$X(X^\top V X)^{-1}$</td><td>$N \times p$</td><td>saige_test.hpp</td></tr>
<tr><td><code>m_XV</code></td><td>$X^\top V$</td><td>$p \times N$</td><td>saige_test.hpp</td></tr>
<tr><td><code>m_XVX_inv_XV</code></td><td>$(X^\top V X)^{-1} X^\top V$</td><td>$p \times N$</td><td>saige_test.hpp</td></tr>
<tr><td><code>m_S_a</code></td><td>$S_a = X^\top r$</td><td>$p$</td><td>saige_test.hpp</td></tr>
<tr><td><code>m_varRatioVal</code></td><td>VR</td><td>scalar</td><td>saige_test.hpp</td></tr>
<tr><td><code>m_SPA_Cutoff</code></td><td>SPA threshold</td><td>scalar (default 2)</td><td>saige_test.hpp</td></tr>
<tr><td><code>m_offset</code></td><td>$\text{offset}$</td><td>$N$</td><td>saige_test.hpp</td></tr>
<tr><td><code>P1Mat</code></td><td>$\sqrt{\text{VR}} \cdot \tilde{G}^\top$</td><td>$m \times N$</td><td>main.cpp</td></tr>
<tr><td><code>P2Mat</code></td><td>$\sqrt{\text{VR}} \cdot P_2$</td><td>$N \times m$</td><td>main.cpp</td></tr>
<tr><td><code>VarMat</code></td><td>$\Phi = P_1 P_2$</td><td>$m \times m$</td><td>main.cpp</td></tr>
<tr><td><code>Score</code></td><td>$S \odot w$</td><td>$m$</td><td>skat.cpp</td></tr>
<tr><td><code>Phi</code></td><td>$(ww^\top) \odot \Phi$</td><td>$m \times m$</td><td>skat.cpp</td></tr>
<tr><td><code>r_corr</code></td><td>$\rho$ grid</td><td>11</td><td>skat.cpp</td></tr>
<tr><td colspan="4" style="background:#34495e; color:white; font-weight:600">Conditional Analysis Variables</td></tr>
<tr><td><code>m_condition_genoIndex</code></td><td>--</td><td>$c$ (vector of marker indices)</td><td>saige_test.hpp</td></tr>
<tr><td><code>m_P2Mat_cond</code></td><td>$P_2$ of conditioning markers</td><td>$N \times c$</td><td>saige_test.hpp</td></tr>
<tr><td><code>m_VarInvMat_cond</code></td><td>$\Phi_{\text{cond}}^{-1}$</td><td>$c \times c$</td><td>saige_test.hpp</td></tr>
<tr><td><code>m_VarMat_cond</code></td><td>$\Phi_{\text{cond}}$</td><td>$c \times c$</td><td>saige_test.hpp</td></tr>
<tr><td><code>m_Tstat_cond</code></td><td>$S_{\text{cond}}$</td><td>$c$</td><td>saige_test.hpp</td></tr>
<tr><td><code>m_G2_Weight_cond</code></td><td>weights for cond. markers</td><td>$c$</td><td>saige_test.hpp</td></tr>
<tr><td colspan="4" style="background:#34495e; color:white; font-weight:600">Sparse GRM Variables</td></tr>
<tr><td><code>m_spSigmaMat</code></td><td>$\Sigma$ (sparse)</td><td>$N \times N$ (sparse)</td><td>saige_test.hpp</td></tr>
<tr><td><code>m_SigmaMat_sp</code></td><td>$\Sigma$ (alt. ref)</td><td>$N \times N$ (sparse)</td><td>saige_test.hpp</td></tr>
<tr><td><code>m_diagSigma</code></td><td>$\text{diag}(\Sigma)$</td><td>$N$</td><td>saige_test.hpp</td></tr>
<tr><td><code>m_flagSparseGRM</code></td><td>--</td><td>bool</td><td>saige_test.hpp</td></tr>
<tr><td><code>m_flagSparseGRM_cur</code></td><td>--</td><td>bool (per-marker toggle)</td><td>saige_test.hpp</td></tr>
<tr><td colspan="4" style="background:#34495e; color:white; font-weight:600">Genotype Format Variables</td></tr>
<tr><td><code>genoType</code></td><td>--</td><td>string: plink/vcf/bgen/pgen</td><td>main.cpp</td></tr>
<tr><td><code>plinkFile</code></td><td>--</td><td>PLINK prefix (.bed/.bim/.fam)</td><td>genotype_reader.hpp</td></tr>
<tr><td><code>vcfFile</code></td><td>--</td><td>VCF/BCF/VCF.GZ path</td><td>genotype_reader.hpp</td></tr>
<tr><td><code>vcfField</code></td><td>--</td><td>GT or DS</td><td>genotype_reader.hpp</td></tr>
<tr><td><code>bgenFile</code></td><td>--</td><td>BGEN v1.2 path</td><td>genotype_reader.hpp</td></tr>
<tr><td><code>pgenFile</code></td><td>--</td><td>PGEN prefix (.pgen/.pvar/.psam)</td><td>genotype_reader.hpp</td></tr>
</table>

</section>


</div> <!-- end #content -->


<!-- ============================================================
     SCROLL-SPY JAVASCRIPT
     ============================================================ -->
<script>
document.addEventListener('DOMContentLoaded', function() {
  const links = document.querySelectorAll('#sidebar nav a');
  const sections = [];

  links.forEach(function(link) {
    const href = link.getAttribute('href');
    if (href && href.startsWith('#')) {
      const section = document.querySelector(href);
      if (section) {
        sections.push({ el: section, link: link });
      }
    }
  });

  function onScroll() {
    const scrollPos = window.scrollY + 80;
    let current = null;

    for (let i = sections.length - 1; i >= 0; i--) {
      if (sections[i].el.offsetTop <= scrollPos) {
        current = sections[i];
        break;
      }
    }

    links.forEach(function(l) { l.classList.remove('active'); });
    if (current) {
      current.link.classList.add('active');
    }
  }

  window.addEventListener('scroll', onScroll);
  onScroll();

  // Smooth scroll for sidebar links
  links.forEach(function(link) {
    link.addEventListener('click', function(e) {
      e.preventDefault();
      const target = document.querySelector(link.getAttribute('href'));
      if (target) {
        target.scrollIntoView({ behavior: 'smooth', block: 'start' });
      }
    });
  });
});
</script>

</body>
</html>
